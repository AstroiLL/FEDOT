{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score as roc_auc\n",
    "\n",
    "from core.composer.chain import Chain\n",
    "from core.composer.gp_composer.gp_composer import \\\n",
    "    GPComposer, GPComposerRequirements\n",
    "from core.composer.visualisation import ComposerVisualiser\n",
    "from core.models.data import InputData\n",
    "from core.repository.model_types_repository import ModelTypesRepository\n",
    "from core.repository.quality_metrics_repository import \\\n",
    "    ClassificationMetricsEnum, MetricsRepository\n",
    "from core.repository.tasks import Task, TaskTypesEnum\n",
    "from core.utils import probs_to_labels\n",
    "from examples.utils import create_multi_clf_examples_from_excel\n",
    "\n",
    "\n",
    "from benchmark.benchmark_utils import get_scoring_case_data_paths\n",
    "from core.composer.chain import Chain\n",
    "from core.composer.node import PrimaryNode, SecondaryNode\n",
    "from core.models.data import InputData\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score as roc_auc\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report, confusion_matrix\n",
    "from benchmark.benchmark_utils import get_scoring_case_data_paths\n",
    "from core.composer.chain import Chain\n",
    "from core.composer.node import PrimaryNode, SecondaryNode\n",
    "from core.models.data import InputData\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "def get_model(train_file_path: str, cur_lead_time: datetime.timedelta = timedelta(minutes=10)):\n",
    "    task = Task(task_type=TaskTypesEnum.classification)\n",
    "    dataset_to_compose = InputData.from_csv(train_file_path, task=task)\n",
    "\n",
    "    # the search of the models provided by the framework\n",
    "    # that can be used as nodes in a chain for the selected task\n",
    "    models_repo = ModelTypesRepository()\n",
    "    available_model_types, _ = models_repo.suitable_model(task_type=task.task_type)\n",
    "\n",
    "    metric_function = MetricsRepository(). \\\n",
    "        metric_by_id(ClassificationMetricsEnum.ROCAUC_penalty)\n",
    "\n",
    "    composer_requirements = GPComposerRequirements(\n",
    "        primary=available_model_types, secondary=available_model_types,\n",
    "        max_lead_time=cur_lead_time, max_arity=3,\n",
    "        max_depth=4, pop_size=20, num_of_generations=100, \n",
    "        crossover_prob = 0.8, mutation_prob = 0.8, \n",
    "        add_single_model_chains = False)\n",
    "\n",
    "    # Create the genetic programming-based composer, that allow to find\n",
    "    # the optimal structure of the composite model\n",
    "    composer = GPComposer()\n",
    "\n",
    "    # run the search of best suitable model\n",
    "    chain_evo_composed = composer.compose_chain(data=dataset_to_compose,\n",
    "                                                initial_chain=None,\n",
    "                                                composer_requirements=composer_requirements,\n",
    "                                                metrics=metric_function, is_visualise=False)\n",
    "    chain_evo_composed.fit(input_data=dataset_to_compose)\n",
    "\n",
    "    return chain_evo_composed\n",
    "\n",
    "\n",
    "def apply_model_to_data(model: Chain, data_path: str):\n",
    "    df, file_path = create_multi_clf_examples_from_excel(data_path, return_df=True)\n",
    "    dataset_to_apply = InputData.from_csv(file_path, with_target=False)\n",
    "    evo_predicted = model.predict(dataset_to_apply)\n",
    "    df['forecast'] = probs_to_labels(evo_predicted.predict)\n",
    "    return df\n",
    "\n",
    "\n",
    "def validate_model_quality(model: Chain, data_path: str):\n",
    "    dataset_to_validate = InputData.from_csv(data_path)\n",
    "    predicted_labels = model.predict(dataset_to_validate).predict\n",
    "\n",
    "    roc_auc_valid = round(roc_auc(y_true=test_data.target,\n",
    "                                  y_score=predicted_labels,\n",
    "                                  multi_class='ovo',\n",
    "                                  average='macro'), 3)\n",
    "    \n",
    "    p = precision_score(y_true=test_data.target,y_pred=predicted_labels.round())\n",
    "    r = recall_score(y_true=test_data.target, y_pred=predicted_labels.round())\n",
    "    a = accuracy_score(y_true=test_data.target, y_pred=predicted_labels.round())\n",
    "    \n",
    "    return roc_auc_valid, p, r, a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation num: 0\n"
     ]
    }
   ],
   "source": [
    "file_path_first = r'./creditcard_under.csv'\n",
    "# file_path_second = r'./data/example2.xlsx'\n",
    "# file_path_third = r'./data/example3.xlsx'\n",
    "\n",
    "#examples/utils.py replace read_excel => read_csv\n",
    "train_file_path, test_file_path = create_multi_clf_examples_from_excel(file_path_first)\n",
    "test_data = InputData.from_csv(test_file_path)\n",
    "#Error!!!!\n",
    "fitted_model = get_model(train_file_path)\n",
    "\n",
    "ComposerVisualiser.visualise(fitted_model, save_path = f'./model3.jpg')\n",
    "\n",
    "roc_auc = validate_model_quality(fitted_model, test_file_path)\n",
    "print(f'ROC AUC metric is {roc_auc}')\n",
    "\n",
    "# final_prediction_first = apply_model_to_data(fitted_model, file_path_second)\n",
    "# print(final_prediction_first['forecast'])\n",
    "\n",
    "# final_prediction_second = apply_model_to_data(fitted_model, file_path_third)\n",
    "# print(final_prediction_second['forecast'])\n",
    "#0.972 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC metric is 0.968\n",
      "PRECISION metric is 0.9263157894736842\n",
      "RECALL metric is 0.8979591836734694\n",
      "ACCURACY metric is 0.9137055837563451\n"
     ]
    }
   ],
   "source": [
    "#mlp + xgboost + logit => mlp\n",
    "roc_auc = validate_model_quality(fitted_model, test_file_path)\n",
    "print(f'ROC AUC metric is {roc_auc[0]}')\n",
    "print(f'PRECISION metric is {roc_auc[1]}')\n",
    "print(f'RECALL metric is {roc_auc[2]}')\n",
    "print(f'ACCURACY metric is {roc_auc[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC metric is 0.975\n",
      "PRECISION metric is 0.9560439560439561\n",
      "RECALL metric is 0.8877551020408163\n",
      "ACCURACY metric is 0.9238578680203046\n"
     ]
    }
   ],
   "source": [
    "# #mlp + xgboost + logit => mlp\n",
    "# roc_auc = validate_model_quality(fitted_model, test_file_path)\n",
    "# print(f'ROC AUC metric is {roc_auc[0]}')\n",
    "# print(f'PRECISION metric is {roc_auc[1]}')\n",
    "# print(f'RECALL metric is {roc_auc[2]}')\n",
    "# print(f'ACCURACY metric is {roc_auc[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC metric is 0.978\n",
      "PRECISION metric is 0.967032967032967\n",
      "RECALL metric is 0.8979591836734694\n",
      "ACCURACY metric is 0.934010152284264\n"
     ]
    }
   ],
   "source": [
    "#direct_data_model + logit => rf\n",
    "# print(f'ROC AUC metric is {roc_auc[0]}')\n",
    "# print(f'PRECISION metric is {roc_auc[1]}')\n",
    "# print(f'RECALL metric is {roc_auc[2]}')\n",
    "# print(f'ACCURACY metric is {roc_auc[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC metric is 0.969\n",
      "PRECISION metric is 0.9263157894736842\n",
      "RECALL metric is 0.8979591836734694\n",
      "ACCURACY metric is 0.9137055837563451\n"
     ]
    }
   ],
   "source": [
    "#Одиночная MLP модель\n",
    "# print(f'ROC AUC metric is {roc_auc[0]}')\n",
    "# print(f'PRECISION metric is {roc_auc[1]}')\n",
    "# print(f'RECALL metric is {roc_auc[2]}')\n",
    "# print(f'ACCURACY metric is {roc_auc[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_first = r'./creditcard_under.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path, test_file_path = create_multi_clf_examples_from_excel(file_path_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = InputData.from_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(task_type=TaskTypesEnum.classification)\n",
    "dataset_to_compose = InputData.from_csv(train_file_path, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_repo = ModelTypesRepository()\n",
    "available_model_types, _ = models_repo.suitable_model(task_type=task.task_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_function = MetricsRepository().metric_by_id(ClassificationMetricsEnum.ROCAUC_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method QualityMetric.get_value_with_penalty of <class 'core.composer.metrics.RocAucMetric'>>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "composer_requirements = GPComposerRequirements(\n",
    "        primary=available_model_types, secondary=available_model_types,\n",
    "        max_lead_time=timedelta(seconds=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "composer_requirements = GPComposerRequirements(\n",
    "        primary='logit', secondary='rf',\n",
    "        max_lead_time=timedelta(seconds=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "composer_requirements = GPComposerRequirements(\n",
    "    primary=available_model_types,\n",
    "    secondary=available_model_types, max_arity=2,\n",
    "    max_depth=3, pop_size=10, num_of_generations=15,\n",
    "    crossover_prob=0.8, mutation_prob=0.8, max_lead_time=timedelta(seconds=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "composer = GPComposer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logit',\n",
       " 'lda',\n",
       " 'qda',\n",
       " 'dt',\n",
       " 'rf',\n",
       " 'mlp',\n",
       " 'knn',\n",
       " 'svc',\n",
       " 'xgboost',\n",
       " 'bernb',\n",
       " 'direct_data_model',\n",
       " 'pca_data_model']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_model_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in chain assessment during composition: Invalid chain configuration: Chain has incorrect models positions. Continue.\n",
      "Error in chain assessment during composition: Invalid chain configuration: Chain has incorrect models positions. Continue.\n",
      "Error in chain assessment during composition: Expected 2D array, got 1D array instead:\n",
      "array=[].\n",
      "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.. Continue.\n",
      "Generation num: 0\n",
      "spent time: 0.3 min\n",
      "Best metric is -0.98769\n",
      "Composition time: 0.3 min\n",
      "Algorithm was terminated due to processing time limit\n",
      "GP composition finished\n"
     ]
    }
   ],
   "source": [
    "chain_evo_composed = composer.compose_chain(data=dataset_to_compose,\n",
    "                                                initial_chain=None,\n",
    "                                                composer_requirements=composer_requirements,\n",
    "                                                metrics=metric_function, \n",
    "                                                is_visualise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain from autoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9892853700379758 0.9971910112359551 0.9010152284263959 0.9998244420549057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9892853700379758"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_chain_from_automl(train_file_path: str, test_file_path: str,\n",
    "                          max_run_time: timedelta = timedelta(minutes=10)):\n",
    "    train_data = InputData.from_csv(train_file_path)\n",
    "    test_data = InputData.from_csv(test_file_path)\n",
    "node_logit.model.external_params = {'max_run_time_sec': max_run_time.seconds}\n",
    "    testing_target = test_data.target\n",
    "\n",
    "    #1 model\n",
    "    chain = Chain()\n",
    "    node_logit = PrimaryNode('logit')\n",
    "    \n",
    "    node_lda = PrimaryNode('lda')\n",
    "    node_rf = SecondaryNode('rf')\n",
    "\n",
    "    node_rf.nodes_from = [node_logit, node_lda]\n",
    "\n",
    "    chain.add_node(node_rf)\n",
    "\n",
    "    chain.fit(train_data)\n",
    "    results = chain.predict(test_data)\n",
    "\n",
    "    roc_auc_value = roc_auc(y_true=testing_target,\n",
    "                            y_score=results.predict)\n",
    "    \n",
    "    \n",
    "    p = precision_score(y_true=testing_target,y_pred=results.predict.round())\n",
    "    r = recall_score(y_true=testing_target, y_pred=results.predict.round())\n",
    "    a = accuracy_score(y_true=testing_target, y_pred=results.predict.round())\n",
    "    \n",
    "    print(roc_auc_value, p, r, a)\n",
    "\n",
    "    return roc_auc_value\n",
    "\n",
    "run_chain_from_automl(train_file_path, test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\creditcard\\\\train.csv',\n",
       " 'C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\creditcard\\\\test.csv')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_path, test_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = InputData.from_csv(train_file_path)\n",
    "test_data = InputData.from_csv(test_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_target = test_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = Chain()\n",
    "node_tpot = PrimaryNode('logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_tpot.model.external_params = {'max_run_time_sec': timedelta(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_lda = PrimaryNode('lda')\n",
    "node_rf = SecondaryNode('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_rf.nodes_from = [node_tpot, node_lda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.add_node(node_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutputData(idx=array([223361., 165061., 238186., ..., 131932., 146867., 121958.]), features=array([[ 1.43352000e+05,  1.95504092e+00, -3.80782711e-01, ...,\n",
       "         4.51682478e-02, -4.71447917e-02,  9.99000000e+00],\n",
       "       [ 1.17173000e+05, -4.00975239e-01, -6.26942769e-01, ...,\n",
       "        -3.70468822e-01, -1.44791686e-01,  4.59000000e+01],\n",
       "       [ 1.49565000e+05,  7.25090164e-02,  8.20565650e-01, ...,\n",
       "         2.06394866e-01,  7.02877702e-02,  1.19900000e+01],\n",
       "       ...,\n",
       "       [ 7.97950000e+04, -1.46608925e-01,  9.92946123e-01, ...,\n",
       "        -1.21139194e-01, -1.96195328e-01,  3.94000000e+00],\n",
       "       [ 8.79310000e+04, -2.94863809e+00,  2.35484929e+00, ...,\n",
       "         4.96912107e-01,  3.35821632e-01,  1.00000000e+00],\n",
       "       [ 7.63810000e+04,  1.23317435e+00, -7.84850501e-01, ...,\n",
       "         1.21657270e-03,  3.85878912e-02,  1.13000000e+02]]), task=Task(task_type=<TaskTypesEnum.classification: ('classification',)>, task_params=None), data_type=<DataTypesEnum.table: 'feature_table'>, predict=array([6.94352513e-05, 6.94352513e-05, 6.94352513e-05, ...,\n",
       "       6.44834432e-04, 6.94352513e-05, 6.94352513e-05]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = chain.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9887529521335848\n"
     ]
    }
   ],
   "source": [
    "roc_auc_value = roc_auc(y_true=testing_target,\n",
    "                        y_score=results.predict)\n",
    "print(roc_auc_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_tuning(nodes_to_tune: str, chain: Chain, train_data: InputData,\n",
    "                 test_data: InputData, local_iter: int,\n",
    "                 tuner_iter_num: int = 50) -> (float, list):\n",
    "    several_iter_scores_test = []\n",
    "\n",
    "    if nodes_to_tune == 'primary':\n",
    "        print('primary_node_tuning')\n",
    "        chain_tune_strategy = chain.fine_tune_primary_nodes\n",
    "    elif nodes_to_tune == 'root':\n",
    "        print('root_node_tuning')\n",
    "        chain_tune_strategy = chain.fine_tune_all_nodes\n",
    "    else:\n",
    "        raise ValueError(f'Invalid type of nodes. Nodes must be primary or root')\n",
    "\n",
    "    for iteration in range(local_iter):\n",
    "        print(f'current local iteration {iteration}')\n",
    "\n",
    "        # Chain tuning\n",
    "        chain_tune_strategy(train_data, iterations=tuner_iter_num)\n",
    "\n",
    "        # After tuning prediction\n",
    "        chain.fit(train_data)\n",
    "        after_tuning_predicted = chain.predict(test_data)\n",
    "\n",
    "        # Metrics\n",
    "        aft_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
    "                                  y_score=after_tuning_predicted.predict)\n",
    "        several_iter_scores_test.append(aft_tun_roc_auc)\n",
    "\n",
    "    return float(np.mean(several_iter_scores_test)), several_iter_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 model\n",
    "def get_simple_chain():\n",
    "    first = PrimaryNode(model_type='logit')\n",
    "    second = PrimaryNode(model_type='lda')\n",
    "    final = SecondaryNode(model_type='rf',\n",
    "                          nodes_from=[first, second])\n",
    "\n",
    "    chain = Chain(final)\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_first = r'./creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\creditcard\\\\train.csv'\n",
    "test_file_path = 'C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\creditcard\\\\test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = InputData.from_csv(train_file_path)\n",
    "test_data = InputData.from_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = get_simple_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutputData(idx=array([223361., 165061., 238186., ..., 131932., 146867., 121958.]), features=array([[ 1.43352000e+05,  1.95504092e+00, -3.80782711e-01, ...,\n",
       "         4.51682478e-02, -4.71447917e-02,  9.99000000e+00],\n",
       "       [ 1.17173000e+05, -4.00975239e-01, -6.26942769e-01, ...,\n",
       "        -3.70468822e-01, -1.44791686e-01,  4.59000000e+01],\n",
       "       [ 1.49565000e+05,  7.25090164e-02,  8.20565650e-01, ...,\n",
       "         2.06394866e-01,  7.02877702e-02,  1.19900000e+01],\n",
       "       ...,\n",
       "       [ 7.97950000e+04, -1.46608925e-01,  9.92946123e-01, ...,\n",
       "        -1.21139194e-01, -1.96195328e-01,  3.94000000e+00],\n",
       "       [ 8.79310000e+04, -2.94863809e+00,  2.35484929e+00, ...,\n",
       "         4.96912107e-01,  3.35821632e-01,  1.00000000e+00],\n",
       "       [ 7.63810000e+04,  1.23317435e+00, -7.84850501e-01, ...,\n",
       "         1.21657270e-03,  3.85878912e-02,  1.13000000e+02]]), task=Task(task_type=<TaskTypesEnum.classification: ('classification',)>, task_params=None), data_type=<DataTypesEnum.table: 'feature_table'>, predict=array([6.96357852e-05, 6.96357852e-05, 6.96357852e-05, ...,\n",
       "       4.78590571e-04, 6.96357852e-05, 6.96357852e-05]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.fit(train_data, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_tuning_predicted = chain.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfr_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
    "                          y_score=before_tuning_predicted.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8283858264\n"
     ]
    }
   ],
   "source": [
    "print(round(bfr_tun_roc_auc, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = precision_score(test_data.target,before_tuning_predicted.predict.round())\n",
    "r = recall_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "a = accuracy_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7640449438202247, 0.6938775510204082, 0.9991046662687406)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, r, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 model\n",
    "def get_simple_chain():\n",
    "    first = PrimaryNode(model_type='xgboost')\n",
    "    second = PrimaryNode(model_type='lda')\n",
    "    final = SecondaryNode(model_type='rf',\n",
    "                          nodes_from=[first, second])\n",
    "\n",
    "    chain = Chain(final)\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_first = r'./creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\creditcard\\\\train.csv'\n",
    "test_file_path = 'C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\creditcard\\\\test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = InputData.from_csv(train_file_path)\n",
    "test_data = InputData.from_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = get_simple_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutputData(idx=array([223361., 165061., 238186., ..., 131932., 146867., 121958.]), features=array([[ 1.43352000e+05,  1.95504092e+00, -3.80782711e-01, ...,\n",
       "         4.51682478e-02, -4.71447917e-02,  9.99000000e+00],\n",
       "       [ 1.17173000e+05, -4.00975239e-01, -6.26942769e-01, ...,\n",
       "        -3.70468822e-01, -1.44791686e-01,  4.59000000e+01],\n",
       "       [ 1.49565000e+05,  7.25090164e-02,  8.20565650e-01, ...,\n",
       "         2.06394866e-01,  7.02877702e-02,  1.19900000e+01],\n",
       "       ...,\n",
       "       [ 7.97950000e+04, -1.46608925e-01,  9.92946123e-01, ...,\n",
       "        -1.21139194e-01, -1.96195328e-01,  3.94000000e+00],\n",
       "       [ 8.79310000e+04, -2.94863809e+00,  2.35484929e+00, ...,\n",
       "         4.96912107e-01,  3.35821632e-01,  1.00000000e+00],\n",
       "       [ 7.63810000e+04,  1.23317435e+00, -7.84850501e-01, ...,\n",
       "         1.21657270e-03,  3.85878912e-02,  1.13000000e+02]]), task=Task(task_type=<TaskTypesEnum.classification: ('classification',)>, task_params=None), data_type=<DataTypesEnum.table: 'feature_table'>, predict=array([0., 0., 0., ..., 0., 0., 0.]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.fit(train_data, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_tuning_predicted = chain.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfr_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
    "                          y_score=before_tuning_predicted.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(round(bfr_tun_roc_auc, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_data.target,before_tuning_predicted.predict.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = precision_score(test_data.target,before_tuning_predicted.predict.round())\n",
    "r = recall_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "a = accuracy_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, r, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced classes to Under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_first = r'./creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./creditcard.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, full_file_path = create_multi_clf_examples_from_excel(file_path_first, return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = InputData.from_csv(full_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Class'])\n",
    "y = df.iloc[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "X_res['Class'] = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82450.0</td>\n",
       "      <td>1.314539</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>-0.666593</td>\n",
       "      <td>0.716564</td>\n",
       "      <td>0.301978</td>\n",
       "      <td>-1.125467</td>\n",
       "      <td>0.388881</td>\n",
       "      <td>-0.288390</td>\n",
       "      <td>-0.132137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170307</td>\n",
       "      <td>-0.429655</td>\n",
       "      <td>-0.141341</td>\n",
       "      <td>-0.200195</td>\n",
       "      <td>0.639491</td>\n",
       "      <td>0.399476</td>\n",
       "      <td>-0.034321</td>\n",
       "      <td>0.031692</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50554.0</td>\n",
       "      <td>-0.798672</td>\n",
       "      <td>1.185093</td>\n",
       "      <td>0.904547</td>\n",
       "      <td>0.694584</td>\n",
       "      <td>0.219041</td>\n",
       "      <td>-0.319295</td>\n",
       "      <td>0.495236</td>\n",
       "      <td>0.139269</td>\n",
       "      <td>-0.760214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202287</td>\n",
       "      <td>0.578699</td>\n",
       "      <td>-0.092245</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>-0.246466</td>\n",
       "      <td>-0.380057</td>\n",
       "      <td>-0.396030</td>\n",
       "      <td>-0.112901</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55125.0</td>\n",
       "      <td>-0.391128</td>\n",
       "      <td>-0.245540</td>\n",
       "      <td>1.122074</td>\n",
       "      <td>-1.308725</td>\n",
       "      <td>-0.639891</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>-0.701304</td>\n",
       "      <td>-0.027315</td>\n",
       "      <td>-2.628854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133485</td>\n",
       "      <td>0.117403</td>\n",
       "      <td>-0.191748</td>\n",
       "      <td>-0.488642</td>\n",
       "      <td>-0.309774</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.163716</td>\n",
       "      <td>0.239582</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116572.0</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>1.065093</td>\n",
       "      <td>-0.987421</td>\n",
       "      <td>-0.029567</td>\n",
       "      <td>0.176376</td>\n",
       "      <td>-1.348539</td>\n",
       "      <td>0.775644</td>\n",
       "      <td>0.134843</td>\n",
       "      <td>-0.149734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355576</td>\n",
       "      <td>0.907570</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>-0.126269</td>\n",
       "      <td>-0.339923</td>\n",
       "      <td>-0.150285</td>\n",
       "      <td>-0.023634</td>\n",
       "      <td>0.042330</td>\n",
       "      <td>57.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90434.0</td>\n",
       "      <td>1.848433</td>\n",
       "      <td>0.373364</td>\n",
       "      <td>0.269272</td>\n",
       "      <td>3.866438</td>\n",
       "      <td>0.088062</td>\n",
       "      <td>0.970447</td>\n",
       "      <td>-0.721945</td>\n",
       "      <td>0.235983</td>\n",
       "      <td>0.683491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103563</td>\n",
       "      <td>0.620954</td>\n",
       "      <td>0.197077</td>\n",
       "      <td>0.692392</td>\n",
       "      <td>-0.206530</td>\n",
       "      <td>-0.021328</td>\n",
       "      <td>-0.019823</td>\n",
       "      <td>-0.042682</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>169142.0</td>\n",
       "      <td>-1.927883</td>\n",
       "      <td>1.125653</td>\n",
       "      <td>-4.518331</td>\n",
       "      <td>1.749293</td>\n",
       "      <td>-1.566487</td>\n",
       "      <td>-2.010494</td>\n",
       "      <td>-0.882850</td>\n",
       "      <td>0.697211</td>\n",
       "      <td>-2.064945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778584</td>\n",
       "      <td>-0.319189</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>-0.294885</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.788395</td>\n",
       "      <td>0.292680</td>\n",
       "      <td>0.147968</td>\n",
       "      <td>390.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>169347.0</td>\n",
       "      <td>1.378559</td>\n",
       "      <td>1.289381</td>\n",
       "      <td>-5.004247</td>\n",
       "      <td>1.411850</td>\n",
       "      <td>0.442581</td>\n",
       "      <td>-1.326536</td>\n",
       "      <td>-1.413170</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>-1.127396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.145640</td>\n",
       "      <td>-0.081049</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.739467</td>\n",
       "      <td>0.389152</td>\n",
       "      <td>0.186637</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>169351.0</td>\n",
       "      <td>-0.676143</td>\n",
       "      <td>1.126366</td>\n",
       "      <td>-2.213700</td>\n",
       "      <td>0.468308</td>\n",
       "      <td>-1.120541</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-2.234739</td>\n",
       "      <td>1.210158</td>\n",
       "      <td>-0.652250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.834108</td>\n",
       "      <td>0.190944</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>-0.739695</td>\n",
       "      <td>0.471111</td>\n",
       "      <td>0.385107</td>\n",
       "      <td>0.194361</td>\n",
       "      <td>77.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>169966.0</td>\n",
       "      <td>-3.113832</td>\n",
       "      <td>0.585864</td>\n",
       "      <td>-5.399730</td>\n",
       "      <td>1.817092</td>\n",
       "      <td>-0.840618</td>\n",
       "      <td>-2.943548</td>\n",
       "      <td>-2.208002</td>\n",
       "      <td>1.058733</td>\n",
       "      <td>-1.632333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>-0.269209</td>\n",
       "      <td>-0.456108</td>\n",
       "      <td>-0.183659</td>\n",
       "      <td>-0.328168</td>\n",
       "      <td>0.606116</td>\n",
       "      <td>0.884876</td>\n",
       "      <td>-0.253700</td>\n",
       "      <td>245.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>170348.0</td>\n",
       "      <td>1.991976</td>\n",
       "      <td>0.158476</td>\n",
       "      <td>-2.583441</td>\n",
       "      <td>0.408670</td>\n",
       "      <td>1.151147</td>\n",
       "      <td>-0.096695</td>\n",
       "      <td>0.223050</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>0.577829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164350</td>\n",
       "      <td>-0.295135</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>-0.450261</td>\n",
       "      <td>0.313267</td>\n",
       "      <td>-0.289617</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>42.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0     82450.0  1.314539  0.590643 -0.666593  0.716564  0.301978 -1.125467   \n",
       "1     50554.0 -0.798672  1.185093  0.904547  0.694584  0.219041 -0.319295   \n",
       "2     55125.0 -0.391128 -0.245540  1.122074 -1.308725 -0.639891  0.008678   \n",
       "3    116572.0 -0.060302  1.065093 -0.987421 -0.029567  0.176376 -1.348539   \n",
       "4     90434.0  1.848433  0.373364  0.269272  3.866438  0.088062  0.970447   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "979  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494   \n",
       "980  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536   \n",
       "981  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n",
       "982  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548   \n",
       "983  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695   \n",
       "\n",
       "           V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0    0.388881 -0.288390 -0.132137  ... -0.170307 -0.429655 -0.141341   \n",
       "1    0.495236  0.139269 -0.760214  ...  0.202287  0.578699 -0.092245   \n",
       "2   -0.701304 -0.027315 -2.628854  ... -0.133485  0.117403 -0.191748   \n",
       "3    0.775644  0.134843 -0.149734  ...  0.355576  0.907570 -0.018454   \n",
       "4   -0.721945  0.235983  0.683491  ...  0.103563  0.620954  0.197077   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "979 -0.882850  0.697211 -2.064945  ...  0.778584 -0.319189  0.639419   \n",
       "980 -1.413170  0.248525 -1.127396  ...  0.370612  0.028234 -0.145640   \n",
       "981 -2.234739  1.210158 -0.652250  ...  0.751826  0.834108  0.190944   \n",
       "982 -2.208002  1.058733 -1.632333  ...  0.583276 -0.269209 -0.456108   \n",
       "983  0.223050 -0.068384  0.577829  ... -0.164350 -0.295135 -0.072173   \n",
       "\n",
       "          V24       V25       V26       V27       V28  Amount  Class  \n",
       "0   -0.200195  0.639491  0.399476 -0.034321  0.031692    0.76      0  \n",
       "1    0.013723 -0.246466 -0.380057 -0.396030 -0.112901    4.18      0  \n",
       "2   -0.488642 -0.309774  0.008100  0.163716  0.239582   15.00      0  \n",
       "3   -0.126269 -0.339923 -0.150285 -0.023634  0.042330   57.00      0  \n",
       "4    0.692392 -0.206530 -0.021328 -0.019823 -0.042682    0.00      0  \n",
       "..        ...       ...       ...       ...       ...     ...    ...  \n",
       "979 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00      1  \n",
       "980 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76      1  \n",
       "981  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89      1  \n",
       "982 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00      1  \n",
       "983 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53      1  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res.to_csv(r'.\\creditcard_under.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced classes to Over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_first = r'./creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./creditcard.csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, full_file_path = create_multi_clf_examples_from_excel(file_path_first, return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = InputData.from_csv(full_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Class'])\n",
    "y = df.iloc[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "X_res['Class'] = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568625</th>\n",
       "      <td>34521.0</td>\n",
       "      <td>1.081234</td>\n",
       "      <td>0.416414</td>\n",
       "      <td>0.862919</td>\n",
       "      <td>2.520863</td>\n",
       "      <td>-0.005021</td>\n",
       "      <td>0.563341</td>\n",
       "      <td>-0.123372</td>\n",
       "      <td>0.223122</td>\n",
       "      <td>-0.673598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159387</td>\n",
       "      <td>-0.305154</td>\n",
       "      <td>0.053620</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>0.375146</td>\n",
       "      <td>-0.106299</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.010559</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568626</th>\n",
       "      <td>53658.0</td>\n",
       "      <td>-1.739341</td>\n",
       "      <td>1.344521</td>\n",
       "      <td>-0.534379</td>\n",
       "      <td>3.195291</td>\n",
       "      <td>-0.416196</td>\n",
       "      <td>-1.261961</td>\n",
       "      <td>-2.340991</td>\n",
       "      <td>0.713004</td>\n",
       "      <td>-1.416265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383180</td>\n",
       "      <td>-0.213952</td>\n",
       "      <td>-0.336640</td>\n",
       "      <td>0.237076</td>\n",
       "      <td>0.246003</td>\n",
       "      <td>-0.044228</td>\n",
       "      <td>0.510729</td>\n",
       "      <td>0.220952</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568627</th>\n",
       "      <td>34687.0</td>\n",
       "      <td>-0.860827</td>\n",
       "      <td>3.131790</td>\n",
       "      <td>-5.052968</td>\n",
       "      <td>5.420941</td>\n",
       "      <td>-2.494141</td>\n",
       "      <td>-1.811287</td>\n",
       "      <td>-5.479117</td>\n",
       "      <td>1.189472</td>\n",
       "      <td>-3.908206</td>\n",
       "      <td>...</td>\n",
       "      <td>1.192694</td>\n",
       "      <td>0.090356</td>\n",
       "      <td>-0.341881</td>\n",
       "      <td>-0.215924</td>\n",
       "      <td>1.053032</td>\n",
       "      <td>0.271139</td>\n",
       "      <td>1.373300</td>\n",
       "      <td>0.691195</td>\n",
       "      <td>19.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568628</th>\n",
       "      <td>40276.0</td>\n",
       "      <td>1.159373</td>\n",
       "      <td>2.844795</td>\n",
       "      <td>-4.050680</td>\n",
       "      <td>4.777701</td>\n",
       "      <td>2.948980</td>\n",
       "      <td>-2.010361</td>\n",
       "      <td>1.744086</td>\n",
       "      <td>-0.410287</td>\n",
       "      <td>-2.450198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176541</td>\n",
       "      <td>-0.433470</td>\n",
       "      <td>-0.529323</td>\n",
       "      <td>-0.597020</td>\n",
       "      <td>1.335954</td>\n",
       "      <td>0.547092</td>\n",
       "      <td>0.009979</td>\n",
       "      <td>0.160769</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568629</th>\n",
       "      <td>102542.0</td>\n",
       "      <td>-1.456876</td>\n",
       "      <td>3.740306</td>\n",
       "      <td>-7.404518</td>\n",
       "      <td>7.440964</td>\n",
       "      <td>-1.549878</td>\n",
       "      <td>-1.661697</td>\n",
       "      <td>-5.757213</td>\n",
       "      <td>1.615011</td>\n",
       "      <td>-2.194881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957897</td>\n",
       "      <td>0.145339</td>\n",
       "      <td>-0.044704</td>\n",
       "      <td>-0.544962</td>\n",
       "      <td>-0.757757</td>\n",
       "      <td>-0.005352</td>\n",
       "      <td>0.318152</td>\n",
       "      <td>-0.323554</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568630 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0            0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1            0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2            1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3            1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4            2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "568625   34521.0  1.081234  0.416414  0.862919  2.520863 -0.005021  0.563341   \n",
       "568626   53658.0 -1.739341  1.344521 -0.534379  3.195291 -0.416196 -1.261961   \n",
       "568627   34687.0 -0.860827  3.131790 -5.052968  5.420941 -2.494141 -1.811287   \n",
       "568628   40276.0  1.159373  2.844795 -4.050680  4.777701  2.948980 -2.010361   \n",
       "568629  102542.0 -1.456876  3.740306 -7.404518  7.440964 -1.549878 -1.661697   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0       0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1      -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2       0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3       0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4       0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "568625 -0.123372  0.223122 -0.673598  ... -0.159387 -0.305154  0.053620   \n",
       "568626 -2.340991  0.713004 -1.416265  ...  0.383180 -0.213952 -0.336640   \n",
       "568627 -5.479117  1.189472 -3.908206  ...  1.192694  0.090356 -0.341881   \n",
       "568628  1.744086 -0.410287 -2.450198  ... -0.176541 -0.433470 -0.529323   \n",
       "568629 -5.757213  1.615011 -2.194881  ...  0.957897  0.145339 -0.044704   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "0       0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1      -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2      -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3      -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4       0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "568625  0.011761  0.375146 -0.106299  0.021008  0.010559    1.52      1  \n",
       "568626  0.237076  0.246003 -0.044228  0.510729  0.220952    0.00      1  \n",
       "568627 -0.215924  1.053032  0.271139  1.373300  0.691195   19.02      1  \n",
       "568628 -0.597020  1.335954  0.547092  0.009979  0.160769    1.00      1  \n",
       "568629 -0.544962 -0.757757 -0.005352  0.318152 -0.323554    2.28      1  \n",
       "\n",
       "[568630 rows x 31 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res.to_csv(r'C:\\Users\\Тимур\\vir\\Scripts\\Fedot\\export_dataframe_over.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on balanced under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_first = r'./export_dataframe.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path, test_file_path = create_multi_clf_examples_from_excel(file_path_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\export_dataframe\\\\train.csv',\n",
       " 'C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\export_dataframe\\\\test.csv')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_path, test_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = InputData.from_csv(train_file_path)\n",
    "test_data = InputData.from_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputData(idx=array([613., 451., 731., 436., 275., 582., 707., 299., 718., 494., 351.,\n",
       "       594., 652., 865., 294.,  66., 377., 682., 755., 107., 139.,  67.,\n",
       "       832., 213., 670., 486., 425., 363.,  76., 298.,  88.,  59., 420.,\n",
       "       237., 848., 221., 362.,  23.,  30., 477., 266., 168., 589., 281.,\n",
       "       493., 643., 669., 479., 280., 535., 778., 490., 758., 734., 588.,\n",
       "       660., 630., 440., 899., 859., 136.,  39., 359., 244., 296., 355.,\n",
       "       937.,  70., 449., 920., 342., 312., 158., 761., 946., 310., 853.,\n",
       "        63., 813., 199., 593., 516., 712., 928.,  96., 959., 321., 542.,\n",
       "       789., 969., 120.,  86., 570., 547., 878., 558., 533., 668., 689.,\n",
       "       615., 887., 792., 254., 909., 921., 798., 184., 836., 819., 979.,\n",
       "       522.,  55., 746., 247., 869., 260.,  72., 655.,  44., 915., 218.,\n",
       "       618., 286., 694., 567., 823., 807., 314., 215., 678., 635., 519.,\n",
       "       394., 259., 926., 333., 465.,  60., 521., 587., 730., 852., 585.,\n",
       "       370., 500., 290., 198., 305., 306., 110., 448., 467., 323., 664.,\n",
       "       235., 814., 808., 408., 616., 361., 210., 137., 485., 552., 604.,\n",
       "       826., 549., 548., 174., 357., 576., 644., 332.,  78.,  29., 265.,\n",
       "       261., 445., 634., 165., 554., 580., 442.,  65., 141., 432., 381.,\n",
       "       688., 656., 870., 828., 917., 292., 209., 506.,  49., 717.]), features=array([[ 4.12330000e+04, -1.06457996e+01,  5.91830666e+00, ...,\n",
       "         2.73328727e-01, -1.52908081e-01,  0.00000000e+00],\n",
       "       [ 1.30800000e+03, -1.37984835e+00,  5.36719684e-01, ...,\n",
       "        -4.38189291e-01, -3.46730811e-01,  4.38000000e+01],\n",
       "       [ 7.23270000e+04, -4.19873461e+00,  1.94120637e-01, ...,\n",
       "         1.24941367e+00, -1.31524644e-01,  2.38900000e+02],\n",
       "       ...,\n",
       "       [ 8.16900000e+03,  8.57321004e-01,  4.09391183e+00, ...,\n",
       "         6.18323805e-01,  1.48468944e-01,  1.00000000e+00],\n",
       "       [ 3.73140000e+04,  1.43845005e+00, -1.10818642e+00, ...,\n",
       "         2.10431479e-02,  3.25145816e-02,  3.00000000e+01],\n",
       "       [ 6.82070000e+04, -1.31926710e+01,  1.27859706e+01, ...,\n",
       "         1.26956636e+00,  9.39407363e-01,  1.00000000e+00]]), task=Task(task_type=<TaskTypesEnum.classification: ('classification',)>, task_params=None), data_type=<DataTypesEnum.table: 'feature_table'>, target=array([1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 0., 1.]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_chain():\n",
    "    first = PrimaryNode(model_type='logit')\n",
    "    second = PrimaryNode(model_type='lda')\n",
    "    final = SecondaryNode(model_type='rf',\n",
    "                          nodes_from=[first, second])\n",
    "\n",
    "    chain = Chain(final)\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = get_simple_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutputData(idx=array([962., 762., 334., 889., 529., 468., 978., 231., 568.,  33.,  31.,\n",
       "       736., 192., 318., 495., 933., 309., 934., 715., 109., 411.,  77.,\n",
       "       680., 923.,  82., 404., 331., 605., 382., 539., 845.,   2., 101.,\n",
       "       371., 462., 453., 208., 884.,   5.,  54., 307., 857., 811., 447.,\n",
       "        97., 597., 204., 514., 628., 944., 527., 344., 854.,  25.,  84.,\n",
       "        10., 892., 770., 621., 365., 752., 118., 350., 250., 705., 940.,\n",
       "       196., 596.,  81., 958., 457., 611., 239., 277., 211., 708., 858.,\n",
       "       713., 227., 842., 497., 785., 482., 636., 346., 450., 824., 352.,\n",
       "         7., 155., 534., 422., 704., 380., 767., 559., 319., 591., 919.,\n",
       "       398., 523., 809., 501., 430., 982., 228., 764., 876., 212.,  79.,\n",
       "       148., 302., 545., 536., 327., 973., 799., 133., 543., 311., 599.,\n",
       "       423.,   0., 316., 697., 797., 328., 525., 970., 433., 172., 125.,\n",
       "       541., 879., 888.,  90., 924., 181., 274., 880.,  69., 291., 131.,\n",
       "       300., 802., 326., 144., 405., 787., 135., 532., 164.,  28., 783.,\n",
       "       193., 901., 629., 169., 728., 140., 173.,   6., 633., 638.,  73.,\n",
       "       849., 861., 238., 145., 781., 234., 220., 456., 481., 132., 974.,\n",
       "       528., 185.,  41., 602., 108., 581.,  56., 388., 424., 788., 846.,\n",
       "        24., 428., 790., 687., 685., 911., 338.,  51., 696., 931., 905.,\n",
       "       662., 264., 530., 673., 483., 507., 429.,  18., 706., 464., 903.,\n",
       "       722., 367.,  83.,  61., 439., 272., 285., 360., 354., 720., 278.,\n",
       "        12., 182., 368., 518., 753., 223., 851., 810., 803., 499., 575.,\n",
       "       601., 176., 657., 784., 578., 513., 786., 163., 248., 626., 902.,\n",
       "       963., 375., 412.,  74., 113., 631., 863., 390., 104., 114., 417.,\n",
       "       910., 409.,  92., 557.,  89., 336., 972., 906., 918., 598., 756.,\n",
       "       603.,  94.,  11., 396., 526.,  43.,  42., 329., 167., 478., 886.,\n",
       "       590., 745., 100., 426., 178., 444., 416., 692., 868., 650., 177.,\n",
       "       395., 667., 939., 945., 675., 383., 941., 257., 531., 335., 606.,\n",
       "        15.,   3., 867., 908., 256., 538., 948., 737., 572., 393., 222.,\n",
       "       179., 289., 967., 324., 583.,   9., 249.,  22., 356., 877., 847.,\n",
       "       340., 431., 544., 820., 203., 622.,  93., 551.,  68., 975., 284.,\n",
       "       872., 434., 153.,  75., 721., 446., 188., 271., 236., 487., 117.,\n",
       "       957., 512., 620., 584., 126., 116., 473., 684.,  57., 665., 914.,\n",
       "       369., 268.,  46., 349., 195., 983., 895., 881., 263., 443., 666.,\n",
       "       304., 341., 951., 149., 124., 907.,  50., 353., 912., 142., 470.,\n",
       "       399., 617., 320.,  19., 796., 981., 795., 407., 537., 740.,  38.,\n",
       "       175., 245., 885., 893., 743., 844., 154., 287., 595., 569., 732.,\n",
       "        17., 127., 322., 255., 649., 949., 190., 115., 625., 180., 301.,\n",
       "       800., 703., 714., 760., 653., 517., 968.,  45., 894., 157., 932.,\n",
       "       171.,  16., 511.,  48., 955., 827., 515., 677., 480., 283., 723.,\n",
       "       927., 225.,  26., 896., 437., 936., 364., 229.,  37., 950., 374.,\n",
       "       469., 952., 837., 695., 716., 194., 925., 850., 503., 954., 817.,\n",
       "       579., 953., 162., 693., 152., 672., 750., 822., 111., 226., 679.,\n",
       "       103., 421., 419., 739., 586., 961., 119.,  53., 151., 403., 930.,\n",
       "       207., 658., 830., 751.,   8., 816.,  36., 452., 651., 253., 303.,\n",
       "       735., 571., 623., 977., 710., 262., 610., 297., 414., 150., 777.,\n",
       "       640., 874., 550., 780., 488., 147., 146., 711., 916., 891., 659.,\n",
       "       348., 463., 325., 186., 123., 839., 608., 143., 943., 197., 609.,\n",
       "       279., 293., 400., 122., 183., 202., 438., 246., 415., 765., 754.,\n",
       "       757., 873., 129., 637., 402., 773., 759., 898., 219., 641., 900.,\n",
       "       741., 793., 904., 624., 825., 749., 386., 956., 509., 267., 806.,\n",
       "       441., 496., 112., 691., 232., 855., 607., 671., 373., 965., 829.,\n",
       "       233., 774., 676., 317., 648., 410., 883., 709., 358., 258., 744.,\n",
       "       627., 632., 282., 376., 384., 224., 938., 801., 472., 347., 505.,\n",
       "       639., 971., 913., 890., 619., 841., 645., 833., 556., 942., 577.,\n",
       "        85., 242., 698., 159., 524.,  35., 540., 170., 654., 935., 843.,\n",
       "       834., 929., 733.,  95., 563., 240., 742., 574., 690., 460., 553.,\n",
       "       864., 206., 392., 794., 397., 766., 835., 217.,   4., 768., 642.,\n",
       "       882., 612., 738., 546., 725., 683.,  98., 804., 727., 573., 406.,\n",
       "       502.,  47.,  32., 779., 200., 134.,  27., 866., 230., 489., 772.,\n",
       "       378., 288., 418., 674., 391., 592., 498., 138.,  62., 471., 647.,\n",
       "       128., 960., 520., 838., 947.,  64., 812.,  14., 156.,  40., 492.,\n",
       "       379., 187., 763., 216., 791.,  52., 337., 748., 719., 724., 295.,\n",
       "       701., 251., 726., 461., 455., 980., 815., 862., 269., 201., 161.,\n",
       "       555., 729., 401., 702., 476., 821., 771., 105., 565., 389.,   1.,\n",
       "       922., 966., 561.,  80., 205.,  34., 775., 508., 427., 454., 366.,\n",
       "        91., 339., 897., 564., 345., 776., 241.,  13., 315., 600., 387.,\n",
       "       273., 166., 840., 976., 646., 818., 484., 964., 504., 831., 243.,\n",
       "       566., 875., 562., 686., 189., 782., 699., 475., 681., 510.,  58.,\n",
       "       474., 560., 856., 747., 252.,  21., 313., 459., 160., 276., 191.,\n",
       "       385., 805., 413., 491., 343., 769., 308., 661., 130., 663., 871.,\n",
       "        99., 372.,  87., 458., 330., 214., 466., 121., 614.,  20., 700.,\n",
       "        71., 106., 270., 860., 435., 102.]), features=array([[ 1.58638000e+05, -5.97611932e+00, -7.19697963e+00, ...,\n",
       "         5.65846302e-01, -1.03410719e+00,  2.96000000e+02],\n",
       "       [ 8.47890000e+04, -1.43086373e+00, -8.02528699e-01, ...,\n",
       "        -1.20351073e-01,  3.55941734e-02,  3.54330000e+02],\n",
       "       [ 1.45056000e+05, -2.71359479e-01,  1.29843749e+00, ...,\n",
       "         1.33778090e-01,  1.70118018e-01,  4.91600000e+01],\n",
       "       ...,\n",
       "       [ 1.28471000e+05,  9.09123839e-01,  1.33765782e+00, ...,\n",
       "         6.52673807e-01,  3.19879228e-01,  6.79000000e+01],\n",
       "       [ 1.22517000e+05,  1.55478327e+00, -1.05940877e+00, ...,\n",
       "        -3.55714131e-02, -8.57818648e-03,  2.29880000e+02],\n",
       "       [ 8.13240000e+04, -2.37304316e+00,  2.56343777e+00, ...,\n",
       "        -9.07652241e-01, -1.48522812e-01,  2.41800000e+01]]), task=Task(task_type=<TaskTypesEnum.classification: ('classification',)>, task_params=None), data_type=<DataTypesEnum.table: 'feature_table'>, predict=array([1.  , 0.76, 0.27, 1.  , 1.  , 0.  , 1.  , 0.01, 1.  , 0.  , 0.07,\n",
       "       0.67, 0.  , 0.  , 1.  , 1.  , 0.2 , 1.  , 0.6 , 0.  , 0.  , 0.  ,\n",
       "       1.  , 1.  , 0.  , 0.  , 0.  , 1.  , 0.  , 1.  , 1.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.07, 1.  , 1.  , 0.  ,\n",
       "       0.04, 1.  , 0.1 , 1.  , 1.  , 1.  , 1.  , 0.  , 0.99, 0.  , 0.36,\n",
       "       0.  , 1.  , 1.  , 1.  , 0.01, 1.  , 0.26, 0.  , 0.  , 1.  , 0.77,\n",
       "       0.06, 1.  , 0.  , 0.69, 0.  , 1.  , 0.  , 0.  , 0.  , 1.  , 1.  ,\n",
       "       1.  , 0.  , 1.  , 1.  , 1.  , 0.  , 1.  , 0.02, 0.  , 1.  , 0.  ,\n",
       "       0.  , 0.  , 1.  , 0.  , 1.  , 0.  , 1.  , 1.  , 0.  , 1.  , 1.  ,\n",
       "       0.  , 1.  , 1.  , 1.  , 0.03, 1.  , 0.  , 1.  , 1.  , 0.  , 0.  ,\n",
       "       0.01, 0.23, 1.  , 1.  , 0.07, 1.  , 1.  , 0.  , 1.  , 0.14, 1.  ,\n",
       "       0.  , 0.01, 0.  , 0.99, 1.  , 0.02, 1.  , 0.97, 0.  , 0.03, 0.  ,\n",
       "       1.  , 1.  , 0.99, 0.01, 1.  , 0.06, 0.06, 1.  , 0.  , 0.03, 0.  ,\n",
       "       0.  , 1.  , 0.  , 0.  , 0.  , 1.  , 0.14, 0.97, 0.  , 0.01, 1.  ,\n",
       "       0.  , 1.  , 1.  , 0.13, 1.  , 0.  , 0.  , 0.  , 1.  , 1.  , 0.  ,\n",
       "       1.  , 1.  , 0.  , 0.  , 1.  , 0.13, 0.  , 0.06, 0.  , 0.11, 0.86,\n",
       "       1.  , 0.  , 0.07, 1.  , 0.1 , 0.59, 0.  , 0.  , 0.  , 1.  , 1.  ,\n",
       "       0.  , 0.03, 1.  , 1.  , 1.  , 1.  , 0.  , 0.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 0.  , 1.  , 1.  , 0.03, 1.  , 0.  , 0.  , 1.  , 0.  , 1.  ,\n",
       "       1.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.14, 0.  , 0.  , 1.  , 0.19,\n",
       "       0.  , 0.01, 0.  , 1.  , 0.89, 0.  , 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 0.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.03, 0.04, 1.  , 0.7 ,\n",
       "       1.  , 0.12, 0.  , 0.  , 0.  , 1.  , 1.  , 0.  , 0.11, 0.  , 0.01,\n",
       "       1.  , 0.  , 0.  , 1.  , 0.09, 0.  , 0.98, 1.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 0.  , 0.  , 0.02, 1.  , 0.02, 0.  , 0.  , 0.05, 0.  , 0.97,\n",
       "       1.  , 1.  , 0.02, 0.  , 0.  , 0.01, 0.03, 1.  , 1.  , 1.  , 0.  ,\n",
       "       0.  , 0.99, 0.79, 1.  , 1.  , 0.04, 0.99, 0.05, 0.9 , 0.  , 1.  ,\n",
       "       0.  , 0.13, 1.  , 1.  , 0.01, 1.  , 1.  , 0.88, 1.  , 0.28, 0.  ,\n",
       "       0.02, 0.  , 1.  , 0.  , 1.  , 0.  , 0.  , 0.03, 0.  , 1.  , 0.88,\n",
       "       0.  , 0.02, 1.  , 1.  , 0.01, 1.  , 0.  , 1.  , 0.  , 1.  , 0.  ,\n",
       "       0.8 , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.01, 0.03, 0.27,\n",
       "       1.  , 1.  , 1.  , 1.  , 0.  , 0.  , 0.  , 1.  , 0.02, 1.  , 1.  ,\n",
       "       0.01, 0.  , 0.  , 0.  , 0.  , 0.85, 1.  , 1.  , 0.01, 0.  , 1.  ,\n",
       "       0.  , 0.  , 1.  , 0.  , 0.  , 1.  , 0.01, 0.  , 1.  , 0.  , 0.  ,\n",
       "       0.  , 1.  , 0.04, 0.  , 1.  , 0.98, 1.  , 0.02, 1.  , 1.  , 0.03,\n",
       "       0.  , 0.18, 1.  , 1.  , 1.  , 0.69, 0.  , 0.  , 1.  , 1.  , 0.74,\n",
       "       0.  , 0.  , 0.  , 0.07, 0.95, 1.  , 0.  , 0.06, 1.  , 0.01, 0.06,\n",
       "       1.  , 0.64, 1.  , 1.  , 0.92, 1.  , 0.91, 0.  , 1.  , 0.  , 1.  ,\n",
       "       0.  , 0.  , 1.  , 0.01, 1.  , 1.  , 1.  , 1.  , 0.  , 0.  , 0.55,\n",
       "       1.  , 0.  , 0.  , 0.65, 0.  , 1.  , 0.  , 0.  , 0.  , 1.  , 0.  ,\n",
       "       0.  , 1.  , 1.  , 1.  , 0.61, 0.03, 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 1.  , 0.02, 1.  , 0.01, 1.  , 1.  , 1.  , 0.07, 0.01, 1.  ,\n",
       "       0.07, 0.  , 0.  , 1.  , 1.  , 1.  , 0.  , 0.  , 0.  , 0.06, 1.  ,\n",
       "       0.01, 1.  , 1.  , 1.  , 0.01, 1.  , 0.  , 0.1 , 0.99, 0.  , 0.04,\n",
       "       1.  , 1.  , 1.  , 0.69, 1.  , 0.07, 1.  , 0.  , 0.  , 0.01, 1.  ,\n",
       "       1.  , 1.  , 1.  , 1.  , 0.  , 0.12, 0.  , 0.63, 1.  , 0.8 , 1.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 1.  , 0.  , 1.  , 0.04, 1.  ,\n",
       "       0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.99,\n",
       "       1.  , 1.  , 0.  , 1.  , 0.  , 1.  , 1.  , 1.  , 0.  , 0.71, 1.  ,\n",
       "       1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.03, 1.  , 1.  , 0.  , 1.  ,\n",
       "       0.  , 1.  , 0.  , 1.  , 0.  , 1.  , 1.  , 1.  , 0.  , 1.  , 1.  ,\n",
       "       0.09, 1.  , 1.  , 0.  , 0.86, 0.  , 0.61, 0.67, 0.  , 0.  , 1.  ,\n",
       "       1.  , 1.  , 0.  , 0.19, 0.11, 0.38, 1.  , 1.  , 0.  , 0.02, 1.  ,\n",
       "       0.99, 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "       0.  , 0.  , 1.  , 0.  , 1.  , 0.01, 1.  , 0.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 1.  , 1.  , 0.  , 1.  , 0.03, 1.  , 1.  , 1.  , 0.  , 1.  ,\n",
       "       0.9 , 0.  , 0.  , 1.  , 0.02, 1.  , 1.  , 0.16, 0.11, 1.  , 1.  ,\n",
       "       1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.01, 1.  , 1.  , 1.  , 0.07,\n",
       "       1.  , 0.13, 0.  , 1.  , 0.  , 0.  , 0.  , 1.  , 0.11, 0.07, 1.  ,\n",
       "       0.04, 0.  , 0.  , 0.95, 0.11, 1.  , 1.  , 0.  , 0.  , 0.  , 0.78,\n",
       "       0.23, 1.  , 1.  , 1.  , 1.  , 0.  , 1.  , 0.  , 0.  , 0.  , 1.  ,\n",
       "       0.  , 0.  , 1.  , 0.  , 1.  , 0.  , 0.01, 1.  , 1.  , 1.  , 0.  ,\n",
       "       1.  , 0.  , 1.  , 0.04, 0.  , 1.  , 1.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "       1.  , 0.86, 0.  , 1.  , 0.34, 1.  , 1.  , 0.  , 1.  , 0.  , 0.01,\n",
       "       1.  , 1.  , 1.  , 0.02, 0.04, 0.  , 1.  , 1.  , 0.  , 0.01, 0.05,\n",
       "       0.  , 0.02, 1.  , 1.  , 0.  , 0.99, 0.  , 0.  , 0.  , 1.  , 0.  ,\n",
       "       0.  , 0.04, 1.  , 0.57, 1.  , 1.  , 0.  , 1.  , 1.  , 1.  , 0.  ,\n",
       "       1.  , 1.  , 1.  , 0.94, 0.01, 1.  , 1.  , 0.  , 1.  , 1.  , 0.02,\n",
       "       0.09, 1.  , 1.  , 0.64, 0.  , 0.  , 0.01, 0.  , 0.03, 0.01, 0.  ,\n",
       "       0.  , 1.  , 0.  , 0.1 , 0.  , 1.  , 0.  , 0.74, 0.  , 1.  , 1.  ,\n",
       "       0.  , 0.14, 0.11, 0.  , 0.  , 0.09, 0.03, 0.  , 1.  , 0.  , 1.  ,\n",
       "       0.  , 0.  , 0.  , 1.  , 0.  , 0.  ]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.fit(train_data, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_tuning_predicted = chain.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9585137085\n"
     ]
    }
   ],
   "source": [
    "bfr_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
    "                          y_score=before_tuning_predicted.predict)\n",
    "print(round(bfr_tun_roc_auc, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9456521739130435, 0.8877551020408163, 0.9187817258883249)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = precision_score(test_data.target,before_tuning_predicted.predict.round())\n",
    "r = recall_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "a = accuracy_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "p, r, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8183704334294213 0.7586206896551724 0.673469387755102 0.9990695551420246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8183704334294213"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_chain_from_automl(train_file_path: str, test_file_path: str,\n",
    "                          max_run_time: timedelta = timedelta(minutes=10)):\n",
    "    train_data = InputData.from_csv(train_file_path)\n",
    "    test_data = InputData.from_csv(test_file_path)\n",
    "    \n",
    "    \n",
    "    testing_target = test_data.target\n",
    "\n",
    "    #1 model\n",
    "    chain = Chain()\n",
    "    node_logit = PrimaryNode('logit')\n",
    "    node_logit.model.external_params = {'max_run_time_sec': max_run_time.seconds}\n",
    "    \n",
    "    node_lda = PrimaryNode('lda')\n",
    "    node_rf = SecondaryNode('rf')\n",
    "\n",
    "    node_rf.nodes_from = [node_logit, node_lda]\n",
    "\n",
    "    chain.add_node(node_rf)\n",
    "\n",
    "    chain.fit(train_data)\n",
    "    results = chain.predict(test_data)\n",
    "\n",
    "    roc_auc_value = roc_auc(y_true=testing_target,\n",
    "                            y_score=results.predict)\n",
    "    \n",
    "    \n",
    "    p = precision_score(y_true=testing_target,y_pred=results.predict.round())\n",
    "    r = recall_score(y_true=testing_target, y_pred=results.predict.round())\n",
    "    a = accuracy_score(y_true=testing_target, y_pred=results.predict.round())\n",
    "    \n",
    "    print(roc_auc_value, p, r, a)\n",
    "\n",
    "    return roc_auc_value\n",
    "\n",
    "run_chain_from_automl(train_file_path, test_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on balanced over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_first = r'./export_dataframe_over.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path, test_file_path = create_multi_clf_examples_from_excel(file_path_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\export_dataframe_over\\\\train.csv',\n",
       " 'C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\export_dataframe_over\\\\test.csv')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_path, test_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = InputData.from_csv(train_file_path)\n",
    "test_data = InputData.from_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_chain():\n",
    "    first = PrimaryNode(model_type='logit')\n",
    "    second = PrimaryNode(model_type='lda')\n",
    "    final = SecondaryNode(model_type='rf',\n",
    "                          nodes_from=[first, second])\n",
    "\n",
    "    chain = Chain(final)\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = get_simple_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutputData(idx=array([ 93824.,  39017., 150139., ...,  62341.,  79795.,  76381.]), features=array([[-3.63280895e+00,  5.43726336e+00, -9.13652148e+00, ...,\n",
       "         1.69360751e+00,  8.57685372e-01,  8.54000000e+00],\n",
       "       [-5.86021027e-01, -3.19820450e-02,  2.15357484e+00, ...,\n",
       "        -1.85795736e-01, -1.29465135e-01,  2.54100000e+01],\n",
       "       [-6.68283192e+00, -2.71426804e+00, -5.77453046e+00, ...,\n",
       "        -5.49876280e-02,  8.23370925e-02,  2.37260000e+02],\n",
       "       ...,\n",
       "       [-5.26775974e+00,  2.50671896e+00, -5.29092482e+00, ...,\n",
       "        -1.48676592e+00,  6.77664105e-01,  1.10000000e+00],\n",
       "       [-1.46608925e-01,  9.92946123e-01,  1.52459137e+00, ...,\n",
       "        -1.21139194e-01, -1.96195328e-01,  3.94000000e+00],\n",
       "       [ 1.23317435e+00, -7.84850501e-01,  3.86783869e-01, ...,\n",
       "         1.21657270e-03,  3.85878912e-02,  1.13000000e+02]]), task=Task(task_type=<TaskTypesEnum.classification: ('classification',)>, task_params=None), data_type=<DataTypesEnum.table: 'feature_table'>, predict=array([0.99995802, 0.        , 1.        , ..., 0.99994947, 0.        ,\n",
       "       0.        ]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.fit(train_data, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_tuning_predicted = chain.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999537225\n"
     ]
    }
   ],
   "source": [
    "bfr_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
    "                          y_score=before_tuning_predicted.predict)\n",
    "print(round(bfr_tun_roc_auc, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9995781569677923, 1.0, 0.9997889664632538)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = precision_score(test_data.target,before_tuning_predicted.predict.round())\n",
    "r = recall_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "a = accuracy_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "p, r, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999577180524802 0.9995641016627412 1.0 0.9997819320120289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999577180524802"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_chain_from_automl(train_file_path: str, test_file_path: str,\n",
    "                          max_run_time: timedelta = timedelta(minutes=10)):\n",
    "    train_data = InputData.from_csv(train_file_path)\n",
    "    test_data = InputData.from_csv(test_file_path)\n",
    "    \n",
    "    \n",
    "    testing_target = test_data.target\n",
    "\n",
    "    #1 model\n",
    "    chain = Chain()\n",
    "    node_logit = PrimaryNode('logit')\n",
    "    node_logit.model.external_params = {'max_run_time_sec': max_run_time.seconds}\n",
    "    \n",
    "    node_lda = PrimaryNode('lda')\n",
    "    node_rf = SecondaryNode('rf')\n",
    "\n",
    "    node_rf.nodes_from = [node_logit, node_lda]\n",
    "\n",
    "    chain.add_node(node_rf)\n",
    "\n",
    "    chain.fit(train_data)\n",
    "    results = chain.predict(test_data)\n",
    "\n",
    "    roc_auc_value = roc_auc(y_true=testing_target,\n",
    "                            y_score=results.predict)\n",
    "    \n",
    "    \n",
    "    p = precision_score(y_true=testing_target,y_pred=results.predict.round())\n",
    "    r = recall_score(y_true=testing_target, y_pred=results.predict.round())\n",
    "    a = accuracy_score(y_true=testing_target, y_pred=results.predict.round())\n",
    "    \n",
    "    print(roc_auc_value, p, r, a)\n",
    "\n",
    "    return roc_auc_value\n",
    "\n",
    "run_chain_from_automl(train_file_path, test_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on balanced predict on full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_first = r'./export_dataframe.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path, test_file_path = create_multi_clf_examples_from_excel(file_path_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\export_dataframe\\\\train.csv',\n",
       " 'C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\export_dataframe\\\\test.csv')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_path, test_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.read_csv('creditcard.csv')\n",
    "data1.to_csv(r'C:\\Users\\Тимур\\vir\\Scripts\\Fedot\\creditcard_with_index.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = r'./creditcard_with_index.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = InputData.from_csv(train_file_path)\n",
    "test_data = InputData.from_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_chain():\n",
    "    first = PrimaryNode(model_type='logit')\n",
    "    second = PrimaryNode(model_type='lda')\n",
    "    final = SecondaryNode(model_type='rf',\n",
    "                          nodes_from=[first, second])\n",
    "\n",
    "    chain = Chain(final)\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = get_simple_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutputData(idx=array([962., 762., 334., 889., 529., 468., 978., 231., 568.,  33.,  31.,\n",
       "       736., 192., 318., 495., 933., 309., 934., 715., 109., 411.,  77.,\n",
       "       680., 923.,  82., 404., 331., 605., 382., 539., 845.,   2., 101.,\n",
       "       371., 462., 453., 208., 884.,   5.,  54., 307., 857., 811., 447.,\n",
       "        97., 597., 204., 514., 628., 944., 527., 344., 854.,  25.,  84.,\n",
       "        10., 892., 770., 621., 365., 752., 118., 350., 250., 705., 940.,\n",
       "       196., 596.,  81., 958., 457., 611., 239., 277., 211., 708., 858.,\n",
       "       713., 227., 842., 497., 785., 482., 636., 346., 450., 824., 352.,\n",
       "         7., 155., 534., 422., 704., 380., 767., 559., 319., 591., 919.,\n",
       "       398., 523., 809., 501., 430., 982., 228., 764., 876., 212.,  79.,\n",
       "       148., 302., 545., 536., 327., 973., 799., 133., 543., 311., 599.,\n",
       "       423.,   0., 316., 697., 797., 328., 525., 970., 433., 172., 125.,\n",
       "       541., 879., 888.,  90., 924., 181., 274., 880.,  69., 291., 131.,\n",
       "       300., 802., 326., 144., 405., 787., 135., 532., 164.,  28., 783.,\n",
       "       193., 901., 629., 169., 728., 140., 173.,   6., 633., 638.,  73.,\n",
       "       849., 861., 238., 145., 781., 234., 220., 456., 481., 132., 974.,\n",
       "       528., 185.,  41., 602., 108., 581.,  56., 388., 424., 788., 846.,\n",
       "        24., 428., 790., 687., 685., 911., 338.,  51., 696., 931., 905.,\n",
       "       662., 264., 530., 673., 483., 507., 429.,  18., 706., 464., 903.,\n",
       "       722., 367.,  83.,  61., 439., 272., 285., 360., 354., 720., 278.,\n",
       "        12., 182., 368., 518., 753., 223., 851., 810., 803., 499., 575.,\n",
       "       601., 176., 657., 784., 578., 513., 786., 163., 248., 626., 902.,\n",
       "       963., 375., 412.,  74., 113., 631., 863., 390., 104., 114., 417.,\n",
       "       910., 409.,  92., 557.,  89., 336., 972., 906., 918., 598., 756.,\n",
       "       603.,  94.,  11., 396., 526.,  43.,  42., 329., 167., 478., 886.,\n",
       "       590., 745., 100., 426., 178., 444., 416., 692., 868., 650., 177.,\n",
       "       395., 667., 939., 945., 675., 383., 941., 257., 531., 335., 606.,\n",
       "        15.,   3., 867., 908., 256., 538., 948., 737., 572., 393., 222.,\n",
       "       179., 289., 967., 324., 583.,   9., 249.,  22., 356., 877., 847.,\n",
       "       340., 431., 544., 820., 203., 622.,  93., 551.,  68., 975., 284.,\n",
       "       872., 434., 153.,  75., 721., 446., 188., 271., 236., 487., 117.,\n",
       "       957., 512., 620., 584., 126., 116., 473., 684.,  57., 665., 914.,\n",
       "       369., 268.,  46., 349., 195., 983., 895., 881., 263., 443., 666.,\n",
       "       304., 341., 951., 149., 124., 907.,  50., 353., 912., 142., 470.,\n",
       "       399., 617., 320.,  19., 796., 981., 795., 407., 537., 740.,  38.,\n",
       "       175., 245., 885., 893., 743., 844., 154., 287., 595., 569., 732.,\n",
       "        17., 127., 322., 255., 649., 949., 190., 115., 625., 180., 301.,\n",
       "       800., 703., 714., 760., 653., 517., 968.,  45., 894., 157., 932.,\n",
       "       171.,  16., 511.,  48., 955., 827., 515., 677., 480., 283., 723.,\n",
       "       927., 225.,  26., 896., 437., 936., 364., 229.,  37., 950., 374.,\n",
       "       469., 952., 837., 695., 716., 194., 925., 850., 503., 954., 817.,\n",
       "       579., 953., 162., 693., 152., 672., 750., 822., 111., 226., 679.,\n",
       "       103., 421., 419., 739., 586., 961., 119.,  53., 151., 403., 930.,\n",
       "       207., 658., 830., 751.,   8., 816.,  36., 452., 651., 253., 303.,\n",
       "       735., 571., 623., 977., 710., 262., 610., 297., 414., 150., 777.,\n",
       "       640., 874., 550., 780., 488., 147., 146., 711., 916., 891., 659.,\n",
       "       348., 463., 325., 186., 123., 839., 608., 143., 943., 197., 609.,\n",
       "       279., 293., 400., 122., 183., 202., 438., 246., 415., 765., 754.,\n",
       "       757., 873., 129., 637., 402., 773., 759., 898., 219., 641., 900.,\n",
       "       741., 793., 904., 624., 825., 749., 386., 956., 509., 267., 806.,\n",
       "       441., 496., 112., 691., 232., 855., 607., 671., 373., 965., 829.,\n",
       "       233., 774., 676., 317., 648., 410., 883., 709., 358., 258., 744.,\n",
       "       627., 632., 282., 376., 384., 224., 938., 801., 472., 347., 505.,\n",
       "       639., 971., 913., 890., 619., 841., 645., 833., 556., 942., 577.,\n",
       "        85., 242., 698., 159., 524.,  35., 540., 170., 654., 935., 843.,\n",
       "       834., 929., 733.,  95., 563., 240., 742., 574., 690., 460., 553.,\n",
       "       864., 206., 392., 794., 397., 766., 835., 217.,   4., 768., 642.,\n",
       "       882., 612., 738., 546., 725., 683.,  98., 804., 727., 573., 406.,\n",
       "       502.,  47.,  32., 779., 200., 134.,  27., 866., 230., 489., 772.,\n",
       "       378., 288., 418., 674., 391., 592., 498., 138.,  62., 471., 647.,\n",
       "       128., 960., 520., 838., 947.,  64., 812.,  14., 156.,  40., 492.,\n",
       "       379., 187., 763., 216., 791.,  52., 337., 748., 719., 724., 295.,\n",
       "       701., 251., 726., 461., 455., 980., 815., 862., 269., 201., 161.,\n",
       "       555., 729., 401., 702., 476., 821., 771., 105., 565., 389.,   1.,\n",
       "       922., 966., 561.,  80., 205.,  34., 775., 508., 427., 454., 366.,\n",
       "        91., 339., 897., 564., 345., 776., 241.,  13., 315., 600., 387.,\n",
       "       273., 166., 840., 976., 646., 818., 484., 964., 504., 831., 243.,\n",
       "       566., 875., 562., 686., 189., 782., 699., 475., 681., 510.,  58.,\n",
       "       474., 560., 856., 747., 252.,  21., 313., 459., 160., 276., 191.,\n",
       "       385., 805., 413., 491., 343., 769., 308., 661., 130., 663., 871.,\n",
       "        99., 372.,  87., 458., 330., 214., 466., 121., 614.,  20., 700.,\n",
       "        71., 106., 270., 860., 435., 102.]), features=array([[ 1.58638000e+05, -5.97611932e+00, -7.19697963e+00, ...,\n",
       "         5.65846302e-01, -1.03410719e+00,  2.96000000e+02],\n",
       "       [ 8.47890000e+04, -1.43086373e+00, -8.02528699e-01, ...,\n",
       "        -1.20351073e-01,  3.55941734e-02,  3.54330000e+02],\n",
       "       [ 1.45056000e+05, -2.71359479e-01,  1.29843749e+00, ...,\n",
       "         1.33778090e-01,  1.70118018e-01,  4.91600000e+01],\n",
       "       ...,\n",
       "       [ 1.28471000e+05,  9.09123839e-01,  1.33765782e+00, ...,\n",
       "         6.52673807e-01,  3.19879228e-01,  6.79000000e+01],\n",
       "       [ 1.22517000e+05,  1.55478327e+00, -1.05940877e+00, ...,\n",
       "        -3.55714131e-02, -8.57818648e-03,  2.29880000e+02],\n",
       "       [ 8.13240000e+04, -2.37304316e+00,  2.56343777e+00, ...,\n",
       "        -9.07652241e-01, -1.48522812e-01,  2.41800000e+01]]), task=Task(task_type=<TaskTypesEnum.classification: ('classification',)>, task_params=None), data_type=<DataTypesEnum.table: 'feature_table'>, predict=array([1.  , 0.73, 0.27, 1.  , 1.  , 0.  , 1.  , 0.06, 1.  , 0.  , 0.08,\n",
       "       0.74, 0.  , 0.  , 1.  , 1.  , 0.26, 1.  , 0.59, 0.  , 0.  , 0.  ,\n",
       "       1.  , 1.  , 0.  , 0.  , 0.  , 1.  , 0.  , 1.  , 1.  , 0.  , 0.  ,\n",
       "       0.01, 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.17, 1.  , 1.  , 0.  ,\n",
       "       0.05, 1.  , 0.08, 1.  , 1.  , 1.  , 1.  , 0.  , 0.99, 0.  , 0.24,\n",
       "       0.  , 1.  , 1.  , 1.  , 0.  , 1.  , 0.25, 0.  , 0.  , 1.  , 0.73,\n",
       "       0.05, 1.  , 0.  , 0.54, 0.01, 1.  , 0.03, 0.  , 0.  , 1.  , 1.  ,\n",
       "       1.  , 0.  , 1.  , 1.  , 1.  , 0.  , 1.  , 0.07, 0.  , 1.  , 0.  ,\n",
       "       0.  , 0.  , 1.  , 0.  , 1.  , 0.  , 1.  , 1.  , 0.  , 1.  , 0.99,\n",
       "       0.  , 1.  , 1.  , 1.  , 0.02, 1.  , 0.  , 1.  , 1.  , 0.  , 0.  ,\n",
       "       0.  , 0.24, 1.  , 1.  , 0.07, 1.  , 1.  , 0.  , 1.  , 0.1 , 1.  ,\n",
       "       0.  , 0.01, 0.  , 0.98, 1.  , 0.02, 1.  , 0.95, 0.  , 0.05, 0.  ,\n",
       "       1.  , 1.  , 0.99, 0.03, 1.  , 0.06, 0.03, 1.  , 0.  , 0.03, 0.  ,\n",
       "       0.  , 1.  , 0.05, 0.  , 0.  , 1.  , 0.11, 0.93, 0.  , 0.01, 1.  ,\n",
       "       0.  , 1.  , 1.  , 0.11, 1.  , 0.  , 0.  , 0.  , 1.  , 1.  , 0.  ,\n",
       "       1.  , 1.  , 0.  , 0.  , 1.  , 0.13, 0.  , 0.16, 0.  , 0.02, 0.91,\n",
       "       1.  , 0.  , 0.  , 1.  , 0.03, 0.71, 0.  , 0.  , 0.  , 1.  , 0.98,\n",
       "       0.  , 0.06, 1.  , 1.  , 1.  , 1.  , 0.  , 0.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 0.  , 1.  , 1.  , 0.03, 1.  , 0.  , 0.  , 0.96, 0.  , 1.  ,\n",
       "       1.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.13, 0.  , 0.  , 1.  , 0.2 ,\n",
       "       0.  , 0.07, 0.  , 1.  , 0.79, 0.  , 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 0.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.02, 0.05, 1.  , 0.76,\n",
       "       1.  , 0.16, 0.  , 0.  , 0.  , 1.  , 1.  , 0.  , 0.18, 0.  , 0.04,\n",
       "       1.  , 0.  , 0.  , 1.  , 0.19, 0.  , 0.99, 1.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 0.04, 0.  , 0.01, 1.  , 0.  , 0.  , 0.  , 0.02, 0.  , 1.  ,\n",
       "       1.  , 1.  , 0.03, 0.  , 0.  , 0.  , 0.02, 1.  , 1.  , 1.  , 0.  ,\n",
       "       0.  , 0.99, 0.87, 1.  , 1.  , 0.06, 0.99, 0.12, 0.9 , 0.  , 1.  ,\n",
       "       0.  , 0.15, 1.  , 1.  , 0.  , 1.  , 1.  , 0.86, 1.  , 0.33, 0.  ,\n",
       "       0.02, 0.  , 1.  , 0.  , 1.  , 0.  , 0.  , 0.03, 0.  , 1.  , 0.91,\n",
       "       0.  , 0.04, 1.  , 1.  , 0.  , 1.  , 0.  , 1.  , 0.  , 1.  , 0.  ,\n",
       "       0.82, 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.01, 0.04, 0.28,\n",
       "       1.  , 1.  , 1.  , 1.  , 0.  , 0.  , 0.  , 1.  , 0.01, 1.  , 1.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.81, 1.  , 1.  , 0.  , 0.01, 1.  ,\n",
       "       0.  , 0.  , 1.  , 0.  , 0.  , 1.  , 0.  , 0.  , 1.  , 0.  , 0.  ,\n",
       "       0.  , 1.  , 0.03, 0.01, 1.  , 0.97, 1.  , 0.06, 1.  , 1.  , 0.01,\n",
       "       0.  , 0.09, 1.  , 1.  , 1.  , 0.55, 0.  , 0.  , 1.  , 1.  , 0.79,\n",
       "       0.  , 0.  , 0.  , 0.11, 0.92, 1.  , 0.  , 0.04, 1.  , 0.  , 0.04,\n",
       "       1.  , 0.71, 1.  , 1.  , 0.79, 1.  , 0.95, 0.  , 1.  , 0.  , 1.  ,\n",
       "       0.  , 0.  , 1.  , 0.01, 1.  , 1.  , 1.  , 1.  , 0.  , 0.  , 0.68,\n",
       "       1.  , 0.  , 0.01, 0.65, 0.  , 1.  , 0.  , 0.  , 0.  , 1.  , 0.  ,\n",
       "       0.  , 1.  , 1.  , 1.  , 0.67, 0.05, 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 1.  , 0.03, 1.  , 0.  , 1.  , 1.  , 1.  , 0.01, 0.  , 1.  ,\n",
       "       0.01, 0.  , 0.  , 1.  , 1.  , 1.  , 0.  , 0.  , 0.  , 0.06, 1.  ,\n",
       "       0.  , 1.  , 1.  , 1.  , 0.  , 1.  , 0.  , 0.17, 0.99, 0.  , 0.04,\n",
       "       1.  , 1.  , 1.  , 0.72, 1.  , 0.13, 1.  , 0.  , 0.  , 0.02, 1.  ,\n",
       "       1.  , 1.  , 1.  , 1.  , 0.  , 0.16, 0.  , 0.55, 1.  , 0.81, 1.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 1.  , 0.  , 1.  , 0.01, 1.  ,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.93,\n",
       "       1.  , 1.  , 0.  , 1.  , 0.  , 1.  , 1.  , 1.  , 0.02, 0.64, 1.  ,\n",
       "       1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.03, 1.  , 1.  , 0.03, 1.  ,\n",
       "       0.  , 1.  , 0.  , 1.  , 0.  , 1.  , 1.  , 1.  , 0.  , 1.  , 1.  ,\n",
       "       0.08, 1.  , 1.  , 0.  , 0.78, 0.  , 0.62, 0.62, 0.  , 0.  , 1.  ,\n",
       "       1.  , 1.  , 0.  , 0.22, 0.21, 0.31, 1.  , 1.  , 0.  , 0.01, 1.  ,\n",
       "       0.98, 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "       0.  , 0.  , 1.  , 0.  , 1.  , 0.03, 1.  , 0.  , 0.99, 1.  , 1.  ,\n",
       "       1.  , 1.  , 1.  , 0.  , 1.  , 0.  , 1.  , 1.  , 1.  , 0.01, 1.  ,\n",
       "       0.94, 0.  , 0.  , 1.  , 0.  , 1.  , 1.  , 0.34, 0.16, 1.  , 1.  ,\n",
       "       1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.01, 1.  , 1.  , 1.  , 0.04,\n",
       "       1.  , 0.1 , 0.  , 1.  , 0.  , 0.  , 0.  , 1.  , 0.2 , 0.11, 1.  ,\n",
       "       0.06, 0.  , 0.  , 0.96, 0.19, 1.  , 1.  , 0.  , 0.  , 0.  , 0.8 ,\n",
       "       0.21, 1.  , 1.  , 1.  , 1.  , 0.  , 1.  , 0.  , 0.  , 0.  , 1.  ,\n",
       "       0.  , 0.  , 1.  , 0.  , 1.  , 0.  , 0.02, 1.  , 1.  , 1.  , 0.  ,\n",
       "       1.  , 0.  , 1.  , 0.03, 0.  , 0.99, 1.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "       1.  , 0.79, 0.  , 1.  , 0.3 , 1.  , 1.  , 0.  , 1.  , 0.  , 0.05,\n",
       "       1.  , 1.  , 1.  , 0.03, 0.02, 0.01, 1.  , 1.  , 0.  , 0.01, 0.02,\n",
       "       0.  , 0.  , 1.  , 1.  , 0.  , 0.97, 0.01, 0.  , 0.  , 1.  , 0.  ,\n",
       "       0.  , 0.05, 1.  , 0.74, 1.  , 1.  , 0.  , 1.  , 1.  , 1.  , 0.  ,\n",
       "       1.  , 1.  , 1.  , 0.85, 0.02, 1.  , 1.  , 0.  , 1.  , 1.  , 0.01,\n",
       "       0.08, 1.  , 1.  , 0.74, 0.  , 0.  , 0.03, 0.  , 0.03, 0.01, 0.  ,\n",
       "       0.01, 1.  , 0.  , 0.05, 0.  , 1.  , 0.  , 0.75, 0.  , 1.  , 1.  ,\n",
       "       0.  , 0.14, 0.15, 0.  , 0.  , 0.1 , 0.03, 0.  , 1.  , 0.  , 1.  ,\n",
       "       0.  , 0.  , 0.  , 1.  , 0.  , 0.  ]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.fit(train_data, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_tuning_predicted = chain.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9854838022\n"
     ]
    }
   ],
   "source": [
    "bfr_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
    "                          y_score=before_tuning_predicted.predict)\n",
    "print(round(bfr_tun_roc_auc, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03659277254782873, 0.9796747967479674, 0.9554083993722065)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = precision_score(y_true=test_data.target,y_pred=before_tuning_predicted.predict.round())\n",
    "r = recall_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "a = accuracy_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "p, r, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03659277254782873"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "482/(482+12690)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2 , 0.09, 0.23, ..., 0.  , 0.  , 0.17])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_tuning_predicted.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[271625,  12690],\n",
       "       [    10,    482]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_data.target, before_tuning_predicted.predict.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796747967479674"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "482/(482+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98    284315\n",
      "         1.0       0.04      0.98      0.07       492\n",
      "\n",
      "    accuracy                           0.96    284807\n",
      "   macro avg       0.52      0.97      0.52    284807\n",
      "weighted avg       1.00      0.96      0.98    284807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_true=test_data.target,y_pred=before_tuning_predicted.predict.round())\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9856229113792114 0.03766507775259827 0.9796747967479674 0.9567250804931059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9856229113792114"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_chain_from_automl(train_file_path: str, test_file_path: str,\n",
    "                          max_run_time: timedelta = timedelta(minutes=10)):\n",
    "    train_data = InputData.from_csv(train_file_path)\n",
    "    test_data = InputData.from_csv(test_file_path)\n",
    "    \n",
    "    \n",
    "    testing_target = test_data.target\n",
    "\n",
    "    #1 model\n",
    "    chain = Chain()\n",
    "    node_logit = PrimaryNode('logit')\n",
    "    node_logit.model.external_params = {'max_run_time_sec': max_run_time.seconds}\n",
    "    \n",
    "    node_lda = PrimaryNode('lda')\n",
    "    node_rf = SecondaryNode('rf')\n",
    "\n",
    "    node_rf.nodes_from = [node_logit, node_lda]\n",
    "\n",
    "    chain.add_node(node_rf)\n",
    "\n",
    "    chain.fit(train_data)\n",
    "    results = chain.predict(test_data)\n",
    "\n",
    "    roc_auc_value = roc_auc(y_true=testing_target,\n",
    "                            y_score=results.predict)\n",
    "    \n",
    "    \n",
    "    p = precision_score(y_true=testing_target,y_pred=results.predict.round())\n",
    "    r = recall_score(y_true=testing_target, y_pred=results.predict.round())\n",
    "    a = accuracy_score(y_true=testing_target, y_pred=results.predict.round())\n",
    "    \n",
    "    print(roc_auc_value, p, r, a)\n",
    "\n",
    "    return roc_auc_value\n",
    "\n",
    "run_chain_from_automl(train_file_path, test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_first = r'./export_dataframe.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path, test_file_path = create_multi_clf_examples_from_excel(file_path_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\export_dataframe\\\\train.csv',\n",
       " 'C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\export_dataframe\\\\test.csv')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_path, test_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = InputData.from_csv(train_file_path)\n",
    "test_data = InputData.from_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_chain():\n",
    "#     first = PrimaryNode(model_type='logit')\n",
    "#     second = PrimaryNode(model_type='lda')\n",
    "    final = PrimaryNode(model_type='rf') #,\n",
    "                          #nodes_from=[first, second])\n",
    "\n",
    "    chain = Chain(final)\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = get_simple_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutputData(idx=array([962., 762., 334., 889., 529., 468., 978., 231., 568.,  33.,  31.,\n",
       "       736., 192., 318., 495., 933., 309., 934., 715., 109., 411.,  77.,\n",
       "       680., 923.,  82., 404., 331., 605., 382., 539., 845.,   2., 101.,\n",
       "       371., 462., 453., 208., 884.,   5.,  54., 307., 857., 811., 447.,\n",
       "        97., 597., 204., 514., 628., 944., 527., 344., 854.,  25.,  84.,\n",
       "        10., 892., 770., 621., 365., 752., 118., 350., 250., 705., 940.,\n",
       "       196., 596.,  81., 958., 457., 611., 239., 277., 211., 708., 858.,\n",
       "       713., 227., 842., 497., 785., 482., 636., 346., 450., 824., 352.,\n",
       "         7., 155., 534., 422., 704., 380., 767., 559., 319., 591., 919.,\n",
       "       398., 523., 809., 501., 430., 982., 228., 764., 876., 212.,  79.,\n",
       "       148., 302., 545., 536., 327., 973., 799., 133., 543., 311., 599.,\n",
       "       423.,   0., 316., 697., 797., 328., 525., 970., 433., 172., 125.,\n",
       "       541., 879., 888.,  90., 924., 181., 274., 880.,  69., 291., 131.,\n",
       "       300., 802., 326., 144., 405., 787., 135., 532., 164.,  28., 783.,\n",
       "       193., 901., 629., 169., 728., 140., 173.,   6., 633., 638.,  73.,\n",
       "       849., 861., 238., 145., 781., 234., 220., 456., 481., 132., 974.,\n",
       "       528., 185.,  41., 602., 108., 581.,  56., 388., 424., 788., 846.,\n",
       "        24., 428., 790., 687., 685., 911., 338.,  51., 696., 931., 905.,\n",
       "       662., 264., 530., 673., 483., 507., 429.,  18., 706., 464., 903.,\n",
       "       722., 367.,  83.,  61., 439., 272., 285., 360., 354., 720., 278.,\n",
       "        12., 182., 368., 518., 753., 223., 851., 810., 803., 499., 575.,\n",
       "       601., 176., 657., 784., 578., 513., 786., 163., 248., 626., 902.,\n",
       "       963., 375., 412.,  74., 113., 631., 863., 390., 104., 114., 417.,\n",
       "       910., 409.,  92., 557.,  89., 336., 972., 906., 918., 598., 756.,\n",
       "       603.,  94.,  11., 396., 526.,  43.,  42., 329., 167., 478., 886.,\n",
       "       590., 745., 100., 426., 178., 444., 416., 692., 868., 650., 177.,\n",
       "       395., 667., 939., 945., 675., 383., 941., 257., 531., 335., 606.,\n",
       "        15.,   3., 867., 908., 256., 538., 948., 737., 572., 393., 222.,\n",
       "       179., 289., 967., 324., 583.,   9., 249.,  22., 356., 877., 847.,\n",
       "       340., 431., 544., 820., 203., 622.,  93., 551.,  68., 975., 284.,\n",
       "       872., 434., 153.,  75., 721., 446., 188., 271., 236., 487., 117.,\n",
       "       957., 512., 620., 584., 126., 116., 473., 684.,  57., 665., 914.,\n",
       "       369., 268.,  46., 349., 195., 983., 895., 881., 263., 443., 666.,\n",
       "       304., 341., 951., 149., 124., 907.,  50., 353., 912., 142., 470.,\n",
       "       399., 617., 320.,  19., 796., 981., 795., 407., 537., 740.,  38.,\n",
       "       175., 245., 885., 893., 743., 844., 154., 287., 595., 569., 732.,\n",
       "        17., 127., 322., 255., 649., 949., 190., 115., 625., 180., 301.,\n",
       "       800., 703., 714., 760., 653., 517., 968.,  45., 894., 157., 932.,\n",
       "       171.,  16., 511.,  48., 955., 827., 515., 677., 480., 283., 723.,\n",
       "       927., 225.,  26., 896., 437., 936., 364., 229.,  37., 950., 374.,\n",
       "       469., 952., 837., 695., 716., 194., 925., 850., 503., 954., 817.,\n",
       "       579., 953., 162., 693., 152., 672., 750., 822., 111., 226., 679.,\n",
       "       103., 421., 419., 739., 586., 961., 119.,  53., 151., 403., 930.,\n",
       "       207., 658., 830., 751.,   8., 816.,  36., 452., 651., 253., 303.,\n",
       "       735., 571., 623., 977., 710., 262., 610., 297., 414., 150., 777.,\n",
       "       640., 874., 550., 780., 488., 147., 146., 711., 916., 891., 659.,\n",
       "       348., 463., 325., 186., 123., 839., 608., 143., 943., 197., 609.,\n",
       "       279., 293., 400., 122., 183., 202., 438., 246., 415., 765., 754.,\n",
       "       757., 873., 129., 637., 402., 773., 759., 898., 219., 641., 900.,\n",
       "       741., 793., 904., 624., 825., 749., 386., 956., 509., 267., 806.,\n",
       "       441., 496., 112., 691., 232., 855., 607., 671., 373., 965., 829.,\n",
       "       233., 774., 676., 317., 648., 410., 883., 709., 358., 258., 744.,\n",
       "       627., 632., 282., 376., 384., 224., 938., 801., 472., 347., 505.,\n",
       "       639., 971., 913., 890., 619., 841., 645., 833., 556., 942., 577.,\n",
       "        85., 242., 698., 159., 524.,  35., 540., 170., 654., 935., 843.,\n",
       "       834., 929., 733.,  95., 563., 240., 742., 574., 690., 460., 553.,\n",
       "       864., 206., 392., 794., 397., 766., 835., 217.,   4., 768., 642.,\n",
       "       882., 612., 738., 546., 725., 683.,  98., 804., 727., 573., 406.,\n",
       "       502.,  47.,  32., 779., 200., 134.,  27., 866., 230., 489., 772.,\n",
       "       378., 288., 418., 674., 391., 592., 498., 138.,  62., 471., 647.,\n",
       "       128., 960., 520., 838., 947.,  64., 812.,  14., 156.,  40., 492.,\n",
       "       379., 187., 763., 216., 791.,  52., 337., 748., 719., 724., 295.,\n",
       "       701., 251., 726., 461., 455., 980., 815., 862., 269., 201., 161.,\n",
       "       555., 729., 401., 702., 476., 821., 771., 105., 565., 389.,   1.,\n",
       "       922., 966., 561.,  80., 205.,  34., 775., 508., 427., 454., 366.,\n",
       "        91., 339., 897., 564., 345., 776., 241.,  13., 315., 600., 387.,\n",
       "       273., 166., 840., 976., 646., 818., 484., 964., 504., 831., 243.,\n",
       "       566., 875., 562., 686., 189., 782., 699., 475., 681., 510.,  58.,\n",
       "       474., 560., 856., 747., 252.,  21., 313., 459., 160., 276., 191.,\n",
       "       385., 805., 413., 491., 343., 769., 308., 661., 130., 663., 871.,\n",
       "        99., 372.,  87., 458., 330., 214., 466., 121., 614.,  20., 700.,\n",
       "        71., 106., 270., 860., 435., 102.]), features=array([[ 1.58638000e+05, -5.97611932e+00, -7.19697963e+00, ...,\n",
       "         5.65846302e-01, -1.03410719e+00,  2.96000000e+02],\n",
       "       [ 8.47890000e+04, -1.43086373e+00, -8.02528699e-01, ...,\n",
       "        -1.20351073e-01,  3.55941734e-02,  3.54330000e+02],\n",
       "       [ 1.45056000e+05, -2.71359479e-01,  1.29843749e+00, ...,\n",
       "         1.33778090e-01,  1.70118018e-01,  4.91600000e+01],\n",
       "       ...,\n",
       "       [ 1.28471000e+05,  9.09123839e-01,  1.33765782e+00, ...,\n",
       "         6.52673807e-01,  3.19879228e-01,  6.79000000e+01],\n",
       "       [ 1.22517000e+05,  1.55478327e+00, -1.05940877e+00, ...,\n",
       "        -3.55714131e-02, -8.57818648e-03,  2.29880000e+02],\n",
       "       [ 8.13240000e+04, -2.37304316e+00,  2.56343777e+00, ...,\n",
       "        -9.07652241e-01, -1.48522812e-01,  2.41800000e+01]]), task=Task(task_type=<TaskTypesEnum.classification: ('classification',)>, task_params=None), data_type=<DataTypesEnum.table: 'feature_table'>, predict=array([0.98, 0.71, 0.14, 1.  , 1.  , 0.03, 1.  , 0.03, 1.  , 0.  , 0.05,\n",
       "       0.62, 0.08, 0.02, 1.  , 1.  , 0.1 , 1.  , 0.69, 0.  , 0.04, 0.  ,\n",
       "       1.  , 0.95, 0.05, 0.01, 0.09, 1.  , 0.01, 1.  , 1.  , 0.05, 0.02,\n",
       "       0.  , 0.  , 0.02, 0.02, 0.98, 0.02, 0.05, 0.15, 0.96, 1.  , 0.  ,\n",
       "       0.04, 0.99, 0.02, 1.  , 0.98, 0.94, 1.  , 0.  , 0.99, 0.03, 0.11,\n",
       "       0.02, 1.  , 1.  , 1.  , 0.11, 0.94, 0.27, 0.07, 0.04, 1.  , 0.89,\n",
       "       0.06, 1.  , 0.04, 0.73, 0.02, 1.  , 0.02, 0.  , 0.  , 0.98, 1.  ,\n",
       "       1.  , 0.  , 1.  , 1.  , 1.  , 0.  , 1.  , 0.04, 0.01, 1.  , 0.14,\n",
       "       0.  , 0.02, 1.  , 0.  , 1.  , 0.  , 1.  , 1.  , 0.  , 1.  , 1.  ,\n",
       "       0.02, 1.  , 1.  , 1.  , 0.1 , 0.98, 0.  , 1.  , 0.97, 0.01, 0.  ,\n",
       "       0.  , 0.14, 1.  , 1.  , 0.13, 0.89, 1.  , 0.  , 1.  , 0.08, 1.  ,\n",
       "       0.  , 0.07, 0.  , 0.93, 1.  , 0.01, 1.  , 1.  , 0.04, 0.07, 0.03,\n",
       "       1.  , 0.99, 0.74, 0.04, 1.  , 0.06, 0.16, 0.99, 0.02, 0.01, 0.03,\n",
       "       0.  , 1.  , 0.11, 0.  , 0.09, 0.99, 0.18, 0.87, 0.  , 0.07, 1.  ,\n",
       "       0.  , 1.  , 1.  , 0.14, 1.  , 0.  , 0.01, 0.02, 0.99, 1.  , 0.01,\n",
       "       1.  , 0.99, 0.  , 0.  , 0.99, 0.08, 0.02, 0.09, 0.04, 0.01, 0.83,\n",
       "       1.  , 0.  , 0.02, 1.  , 0.02, 0.74, 0.01, 0.02, 0.  , 1.  , 1.  ,\n",
       "       0.03, 0.01, 1.  , 1.  , 1.  , 1.  , 0.03, 0.01, 0.99, 1.  , 1.  ,\n",
       "       0.9 , 0.  , 0.98, 1.  , 0.19, 1.  , 0.02, 0.03, 0.95, 0.02, 1.  ,\n",
       "       1.  , 0.09, 0.  , 0.  , 0.02, 0.05, 0.03, 0.03, 0.  , 1.  , 0.02,\n",
       "       0.02, 0.08, 0.01, 1.  , 0.83, 0.02, 0.98, 1.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 0.01, 1.  , 1.  , 0.99, 1.  , 1.  , 0.06, 0.01, 1.  , 0.68,\n",
       "       0.99, 0.01, 0.  , 0.11, 0.  , 1.  , 1.  , 0.04, 0.1 , 0.02, 0.  ,\n",
       "       0.98, 0.  , 0.01, 1.  , 0.08, 0.03, 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 0.15, 0.01, 0.01, 1.  , 0.17, 0.06, 0.  , 0.16, 0.1 , 1.  ,\n",
       "       1.  , 1.  , 0.08, 0.05, 0.07, 0.06, 0.2 , 1.  , 0.99, 1.  , 0.01,\n",
       "       0.  , 1.  , 0.77, 0.99, 0.99, 0.18, 0.96, 0.08, 0.91, 0.08, 1.  ,\n",
       "       0.07, 0.01, 0.97, 1.  , 0.  , 0.99, 1.  , 0.72, 1.  , 0.25, 0.04,\n",
       "       0.1 , 0.03, 1.  , 0.02, 1.  , 0.02, 0.01, 0.01, 0.  , 0.99, 0.76,\n",
       "       0.05, 0.18, 1.  , 1.  , 0.05, 1.  , 0.02, 1.  , 0.07, 1.  , 0.  ,\n",
       "       0.85, 0.01, 0.  , 0.02, 1.  , 0.  , 0.02, 0.  , 0.08, 0.  , 0.24,\n",
       "       1.  , 1.  , 1.  , 1.  , 0.03, 0.03, 0.04, 0.98, 0.01, 1.  , 0.93,\n",
       "       0.01, 0.02, 0.05, 0.  , 0.02, 0.82, 1.  , 0.99, 0.01, 0.  , 1.  ,\n",
       "       0.05, 0.02, 1.  , 0.02, 0.  , 1.  , 0.06, 0.  , 1.  , 0.  , 0.01,\n",
       "       0.12, 1.  , 0.11, 0.  , 1.  , 0.97, 1.  , 0.02, 1.  , 1.  , 0.04,\n",
       "       0.03, 0.  , 1.  , 0.96, 1.  , 0.71, 0.01, 0.1 , 0.87, 1.  , 0.66,\n",
       "       0.01, 0.02, 0.  , 0.01, 0.75, 1.  , 0.02, 0.03, 1.  , 0.03, 0.01,\n",
       "       1.  , 0.68, 1.  , 1.  , 0.67, 1.  , 0.73, 0.  , 1.  , 0.02, 1.  ,\n",
       "       0.05, 0.01, 1.  , 0.03, 1.  , 1.  , 1.  , 1.  , 0.06, 0.01, 0.71,\n",
       "       0.98, 0.01, 0.  , 0.63, 0.  , 1.  , 0.04, 0.03, 0.14, 1.  , 0.03,\n",
       "       0.01, 1.  , 1.  , 0.98, 0.7 , 0.  , 1.  , 0.99, 1.  , 0.99, 0.99,\n",
       "       1.  , 0.96, 0.  , 0.93, 0.06, 1.  , 0.96, 1.  , 0.03, 0.03, 1.  ,\n",
       "       0.  , 0.01, 0.01, 1.  , 1.  , 1.  , 0.07, 0.11, 0.01, 0.01, 0.99,\n",
       "       0.13, 1.  , 1.  , 1.  , 0.03, 1.  , 0.  , 0.08, 1.  , 0.07, 0.  ,\n",
       "       0.97, 1.  , 1.  , 0.75, 0.97, 0.04, 1.  , 0.03, 0.  , 0.05, 0.87,\n",
       "       1.  , 0.86, 1.  , 0.96, 0.  , 0.05, 0.02, 0.75, 0.99, 0.72, 1.  ,\n",
       "       0.04, 0.03, 0.06, 0.01, 0.  , 1.  , 1.  , 0.01, 0.99, 0.14, 1.  ,\n",
       "       0.08, 0.  , 0.  , 0.08, 0.  , 0.  , 0.  , 0.03, 0.04, 1.  , 1.  ,\n",
       "       1.  , 0.88, 0.13, 1.  , 0.06, 0.86, 1.  , 0.95, 0.  , 0.65, 1.  ,\n",
       "       1.  , 1.  , 1.  , 0.99, 0.98, 0.99, 0.01, 1.  , 1.  , 0.09, 1.  ,\n",
       "       0.  , 0.99, 0.  , 1.  , 0.03, 1.  , 1.  , 1.  , 0.  , 1.  , 0.99,\n",
       "       0.18, 0.83, 1.  , 0.02, 0.78, 0.09, 0.76, 0.72, 0.01, 0.  , 1.  ,\n",
       "       1.  , 1.  , 0.01, 0.2 , 0.1 , 0.22, 1.  , 1.  , 0.  , 0.08, 1.  ,\n",
       "       0.97, 1.  , 0.87, 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.78,\n",
       "       0.09, 0.01, 1.  , 0.  , 0.96, 0.13, 1.  , 0.  , 1.  , 1.  , 1.  ,\n",
       "       0.97, 0.98, 1.  , 0.02, 1.  , 0.09, 1.  , 1.  , 0.99, 0.  , 1.  ,\n",
       "       0.74, 0.  , 0.02, 1.  , 0.16, 1.  , 1.  , 0.13, 0.17, 1.  , 1.  ,\n",
       "       1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.02, 1.  , 0.99, 1.  , 0.02,\n",
       "       1.  , 0.02, 0.02, 1.  , 0.  , 0.12, 0.02, 1.  , 0.14, 0.08, 0.83,\n",
       "       0.04, 0.03, 0.05, 0.79, 0.01, 1.  , 1.  , 0.  , 0.01, 0.  , 0.64,\n",
       "       0.04, 1.  , 1.  , 1.  , 1.  , 0.01, 1.  , 0.02, 0.  , 0.02, 1.  ,\n",
       "       0.02, 0.  , 0.99, 0.02, 1.  , 0.  , 0.01, 1.  , 1.  , 1.  , 0.02,\n",
       "       1.  , 0.01, 1.  , 0.  , 0.08, 0.99, 1.  , 0.99, 0.05, 0.05, 0.01,\n",
       "       1.  , 0.81, 0.  , 0.99, 0.16, 1.  , 1.  , 0.07, 1.  , 0.  , 0.  ,\n",
       "       0.99, 1.  , 1.  , 0.04, 0.21, 0.  , 1.  , 1.  , 0.01, 0.01, 0.05,\n",
       "       0.12, 0.01, 0.95, 1.  , 0.  , 0.97, 0.01, 0.02, 0.06, 1.  , 0.01,\n",
       "       0.01, 0.  , 1.  , 0.76, 1.  , 0.99, 0.  , 0.98, 1.  , 1.  , 0.03,\n",
       "       1.  , 0.97, 1.  , 0.77, 0.13, 0.98, 1.  , 0.  , 1.  , 1.  , 0.02,\n",
       "       0.  , 1.  , 0.97, 0.63, 0.  , 0.02, 0.02, 0.02, 0.06, 0.02, 0.05,\n",
       "       0.  , 1.  , 0.07, 0.09, 0.  , 1.  , 0.02, 0.75, 0.02, 1.  , 1.  ,\n",
       "       0.02, 0.23, 0.13, 0.  , 0.04, 0.09, 0.03, 0.03, 1.  , 0.05, 0.99,\n",
       "       0.01, 0.05, 0.  , 1.  , 0.01, 0.04]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.fit(train_data, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_tuning_predicted = chain.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9788188002\n"
     ]
    }
   ],
   "source": [
    "bfr_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
    "                          y_score=before_tuning_predicted.predict)\n",
    "print(round(bfr_tun_roc_auc, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9560439560439561, 0.8877551020408163, 0.9238578680203046)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = precision_score(test_data.target,before_tuning_predicted.predict.round())\n",
    "r = recall_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "a = accuracy_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "p, r, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logit',\n",
       " 'lda',\n",
       " 'qda',\n",
       " 'dt',\n",
       " 'rf',\n",
       " 'mlp',\n",
       " 'knn',\n",
       " 'svc',\n",
       " 'xgboost',\n",
       " 'bernb',\n",
       " 'direct_data_model']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_model_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logit'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_model_types[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_chain(model_type):\n",
    "    \n",
    "    final = PrimaryNode(model_type='{}'.format(model_type))                    \n",
    "    chain = Chain(final)\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = get_simple_chain('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutputData(idx=array([962., 762., 334., 889., 529., 468., 978., 231., 568.,  33.,  31.,\n",
       "       736., 192., 318., 495., 933., 309., 934., 715., 109., 411.,  77.,\n",
       "       680., 923.,  82., 404., 331., 605., 382., 539., 845.,   2., 101.,\n",
       "       371., 462., 453., 208., 884.,   5.,  54., 307., 857., 811., 447.,\n",
       "        97., 597., 204., 514., 628., 944., 527., 344., 854.,  25.,  84.,\n",
       "        10., 892., 770., 621., 365., 752., 118., 350., 250., 705., 940.,\n",
       "       196., 596.,  81., 958., 457., 611., 239., 277., 211., 708., 858.,\n",
       "       713., 227., 842., 497., 785., 482., 636., 346., 450., 824., 352.,\n",
       "         7., 155., 534., 422., 704., 380., 767., 559., 319., 591., 919.,\n",
       "       398., 523., 809., 501., 430., 982., 228., 764., 876., 212.,  79.,\n",
       "       148., 302., 545., 536., 327., 973., 799., 133., 543., 311., 599.,\n",
       "       423.,   0., 316., 697., 797., 328., 525., 970., 433., 172., 125.,\n",
       "       541., 879., 888.,  90., 924., 181., 274., 880.,  69., 291., 131.,\n",
       "       300., 802., 326., 144., 405., 787., 135., 532., 164.,  28., 783.,\n",
       "       193., 901., 629., 169., 728., 140., 173.,   6., 633., 638.,  73.,\n",
       "       849., 861., 238., 145., 781., 234., 220., 456., 481., 132., 974.,\n",
       "       528., 185.,  41., 602., 108., 581.,  56., 388., 424., 788., 846.,\n",
       "        24., 428., 790., 687., 685., 911., 338.,  51., 696., 931., 905.,\n",
       "       662., 264., 530., 673., 483., 507., 429.,  18., 706., 464., 903.,\n",
       "       722., 367.,  83.,  61., 439., 272., 285., 360., 354., 720., 278.,\n",
       "        12., 182., 368., 518., 753., 223., 851., 810., 803., 499., 575.,\n",
       "       601., 176., 657., 784., 578., 513., 786., 163., 248., 626., 902.,\n",
       "       963., 375., 412.,  74., 113., 631., 863., 390., 104., 114., 417.,\n",
       "       910., 409.,  92., 557.,  89., 336., 972., 906., 918., 598., 756.,\n",
       "       603.,  94.,  11., 396., 526.,  43.,  42., 329., 167., 478., 886.,\n",
       "       590., 745., 100., 426., 178., 444., 416., 692., 868., 650., 177.,\n",
       "       395., 667., 939., 945., 675., 383., 941., 257., 531., 335., 606.,\n",
       "        15.,   3., 867., 908., 256., 538., 948., 737., 572., 393., 222.,\n",
       "       179., 289., 967., 324., 583.,   9., 249.,  22., 356., 877., 847.,\n",
       "       340., 431., 544., 820., 203., 622.,  93., 551.,  68., 975., 284.,\n",
       "       872., 434., 153.,  75., 721., 446., 188., 271., 236., 487., 117.,\n",
       "       957., 512., 620., 584., 126., 116., 473., 684.,  57., 665., 914.,\n",
       "       369., 268.,  46., 349., 195., 983., 895., 881., 263., 443., 666.,\n",
       "       304., 341., 951., 149., 124., 907.,  50., 353., 912., 142., 470.,\n",
       "       399., 617., 320.,  19., 796., 981., 795., 407., 537., 740.,  38.,\n",
       "       175., 245., 885., 893., 743., 844., 154., 287., 595., 569., 732.,\n",
       "        17., 127., 322., 255., 649., 949., 190., 115., 625., 180., 301.,\n",
       "       800., 703., 714., 760., 653., 517., 968.,  45., 894., 157., 932.,\n",
       "       171.,  16., 511.,  48., 955., 827., 515., 677., 480., 283., 723.,\n",
       "       927., 225.,  26., 896., 437., 936., 364., 229.,  37., 950., 374.,\n",
       "       469., 952., 837., 695., 716., 194., 925., 850., 503., 954., 817.,\n",
       "       579., 953., 162., 693., 152., 672., 750., 822., 111., 226., 679.,\n",
       "       103., 421., 419., 739., 586., 961., 119.,  53., 151., 403., 930.,\n",
       "       207., 658., 830., 751.,   8., 816.,  36., 452., 651., 253., 303.,\n",
       "       735., 571., 623., 977., 710., 262., 610., 297., 414., 150., 777.,\n",
       "       640., 874., 550., 780., 488., 147., 146., 711., 916., 891., 659.,\n",
       "       348., 463., 325., 186., 123., 839., 608., 143., 943., 197., 609.,\n",
       "       279., 293., 400., 122., 183., 202., 438., 246., 415., 765., 754.,\n",
       "       757., 873., 129., 637., 402., 773., 759., 898., 219., 641., 900.,\n",
       "       741., 793., 904., 624., 825., 749., 386., 956., 509., 267., 806.,\n",
       "       441., 496., 112., 691., 232., 855., 607., 671., 373., 965., 829.,\n",
       "       233., 774., 676., 317., 648., 410., 883., 709., 358., 258., 744.,\n",
       "       627., 632., 282., 376., 384., 224., 938., 801., 472., 347., 505.,\n",
       "       639., 971., 913., 890., 619., 841., 645., 833., 556., 942., 577.,\n",
       "        85., 242., 698., 159., 524.,  35., 540., 170., 654., 935., 843.,\n",
       "       834., 929., 733.,  95., 563., 240., 742., 574., 690., 460., 553.,\n",
       "       864., 206., 392., 794., 397., 766., 835., 217.,   4., 768., 642.,\n",
       "       882., 612., 738., 546., 725., 683.,  98., 804., 727., 573., 406.,\n",
       "       502.,  47.,  32., 779., 200., 134.,  27., 866., 230., 489., 772.,\n",
       "       378., 288., 418., 674., 391., 592., 498., 138.,  62., 471., 647.,\n",
       "       128., 960., 520., 838., 947.,  64., 812.,  14., 156.,  40., 492.,\n",
       "       379., 187., 763., 216., 791.,  52., 337., 748., 719., 724., 295.,\n",
       "       701., 251., 726., 461., 455., 980., 815., 862., 269., 201., 161.,\n",
       "       555., 729., 401., 702., 476., 821., 771., 105., 565., 389.,   1.,\n",
       "       922., 966., 561.,  80., 205.,  34., 775., 508., 427., 454., 366.,\n",
       "        91., 339., 897., 564., 345., 776., 241.,  13., 315., 600., 387.,\n",
       "       273., 166., 840., 976., 646., 818., 484., 964., 504., 831., 243.,\n",
       "       566., 875., 562., 686., 189., 782., 699., 475., 681., 510.,  58.,\n",
       "       474., 560., 856., 747., 252.,  21., 313., 459., 160., 276., 191.,\n",
       "       385., 805., 413., 491., 343., 769., 308., 661., 130., 663., 871.,\n",
       "        99., 372.,  87., 458., 330., 214., 466., 121., 614.,  20., 700.,\n",
       "        71., 106., 270., 860., 435., 102.]), features=array([[ 1.58638000e+05, -5.97611932e+00, -7.19697963e+00, ...,\n",
       "         5.65846302e-01, -1.03410719e+00,  2.96000000e+02],\n",
       "       [ 8.47890000e+04, -1.43086373e+00, -8.02528699e-01, ...,\n",
       "        -1.20351073e-01,  3.55941734e-02,  3.54330000e+02],\n",
       "       [ 1.45056000e+05, -2.71359479e-01,  1.29843749e+00, ...,\n",
       "         1.33778090e-01,  1.70118018e-01,  4.91600000e+01],\n",
       "       ...,\n",
       "       [ 1.28471000e+05,  9.09123839e-01,  1.33765782e+00, ...,\n",
       "         6.52673807e-01,  3.19879228e-01,  6.79000000e+01],\n",
       "       [ 1.22517000e+05,  1.55478327e+00, -1.05940877e+00, ...,\n",
       "        -3.55714131e-02, -8.57818648e-03,  2.29880000e+02],\n",
       "       [ 8.13240000e+04, -2.37304316e+00,  2.56343777e+00, ...,\n",
       "        -9.07652241e-01, -1.48522812e-01,  2.41800000e+01]]), task=Task(task_type=<TaskTypesEnum.classification: ('classification',)>, task_params=None), data_type=<DataTypesEnum.table: 'feature_table'>, predict=array([0.99, 0.67, 0.13, 1.  , 1.  , 0.02, 1.  , 0.08, 1.  , 0.  , 0.06,\n",
       "       0.66, 0.03, 0.  , 1.  , 1.  , 0.08, 1.  , 0.74, 0.  , 0.03, 0.03,\n",
       "       1.  , 0.99, 0.03, 0.01, 0.07, 1.  , 0.  , 1.  , 1.  , 0.06, 0.  ,\n",
       "       0.01, 0.  , 0.  , 0.  , 1.  , 0.  , 0.06, 0.19, 0.95, 1.  , 0.  ,\n",
       "       0.08, 0.99, 0.03, 1.  , 1.  , 0.97, 1.  , 0.02, 1.  , 0.05, 0.17,\n",
       "       0.02, 1.  , 1.  , 1.  , 0.08, 1.  , 0.27, 0.06, 0.02, 0.98, 0.85,\n",
       "       0.01, 0.96, 0.01, 0.71, 0.05, 1.  , 0.02, 0.01, 0.02, 0.99, 1.  ,\n",
       "       1.  , 0.  , 1.  , 0.99, 1.  , 0.  , 1.  , 0.05, 0.01, 0.99, 0.07,\n",
       "       0.  , 0.03, 1.  , 0.  , 1.  , 0.01, 1.  , 1.  , 0.  , 1.  , 1.  ,\n",
       "       0.  , 1.  , 1.  , 1.  , 0.15, 0.99, 0.  , 1.  , 1.  , 0.02, 0.01,\n",
       "       0.  , 0.12, 1.  , 1.  , 0.14, 0.83, 1.  , 0.02, 1.  , 0.08, 1.  ,\n",
       "       0.  , 0.08, 0.01, 0.98, 1.  , 0.02, 1.  , 1.  , 0.04, 0.07, 0.07,\n",
       "       1.  , 1.  , 0.78, 0.03, 1.  , 0.04, 0.08, 0.97, 0.02, 0.02, 0.03,\n",
       "       0.  , 1.  , 0.03, 0.  , 0.06, 1.  , 0.15, 0.81, 0.  , 0.07, 1.  ,\n",
       "       0.  , 0.99, 1.  , 0.15, 1.  , 0.  , 0.  , 0.03, 0.99, 1.  , 0.01,\n",
       "       1.  , 1.  , 0.  , 0.  , 0.98, 0.  , 0.  , 0.11, 0.01, 0.02, 0.71,\n",
       "       1.  , 0.01, 0.02, 1.  , 0.01, 0.72, 0.  , 0.  , 0.02, 1.  , 1.  ,\n",
       "       0.  , 0.02, 1.  , 1.  , 1.  , 1.  , 0.02, 0.02, 1.  , 1.  , 1.  ,\n",
       "       0.85, 0.  , 0.97, 1.  , 0.15, 1.  , 0.03, 0.03, 0.91, 0.02, 1.  ,\n",
       "       1.  , 0.07, 0.04, 0.  , 0.01, 0.01, 0.08, 0.02, 0.02, 1.  , 0.  ,\n",
       "       0.02, 0.1 , 0.  , 0.98, 0.84, 0.03, 0.99, 1.  , 1.  , 0.99, 1.  ,\n",
       "       1.  , 0.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.08, 0.  , 1.  , 0.74,\n",
       "       0.96, 0.01, 0.  , 0.12, 0.  , 1.  , 1.  , 0.04, 0.06, 0.  , 0.01,\n",
       "       0.99, 0.  , 0.  , 1.  , 0.07, 0.05, 0.98, 1.  , 0.96, 1.  , 1.  ,\n",
       "       1.  , 0.09, 0.02, 0.03, 1.  , 0.22, 0.02, 0.04, 0.1 , 0.06, 1.  ,\n",
       "       1.  , 0.99, 0.11, 0.06, 0.08, 0.06, 0.14, 1.  , 1.  , 1.  , 0.  ,\n",
       "       0.01, 0.99, 0.74, 0.98, 1.  , 0.17, 0.96, 0.12, 0.81, 0.07, 1.  ,\n",
       "       0.06, 0.02, 0.99, 1.  , 0.  , 1.  , 1.  , 0.81, 1.  , 0.32, 0.06,\n",
       "       0.09, 0.04, 1.  , 0.  , 1.  , 0.01, 0.  , 0.  , 0.  , 1.  , 0.88,\n",
       "       0.05, 0.21, 1.  , 1.  , 0.17, 1.  , 0.02, 1.  , 0.07, 0.99, 0.  ,\n",
       "       0.87, 0.01, 0.  , 0.  , 1.  , 0.  , 0.02, 0.  , 0.14, 0.  , 0.2 ,\n",
       "       1.  , 1.  , 1.  , 1.  , 0.02, 0.05, 0.07, 0.98, 0.01, 1.  , 0.95,\n",
       "       0.01, 0.02, 0.04, 0.  , 0.03, 0.77, 1.  , 0.99, 0.03, 0.03, 0.99,\n",
       "       0.08, 0.04, 1.  , 0.02, 0.  , 1.  , 0.05, 0.  , 1.  , 0.01, 0.  ,\n",
       "       0.1 , 1.  , 0.11, 0.  , 1.  , 0.98, 1.  , 0.02, 1.  , 1.  , 0.05,\n",
       "       0.03, 0.01, 1.  , 1.  , 0.99, 0.73, 0.01, 0.08, 0.87, 1.  , 0.59,\n",
       "       0.02, 0.05, 0.03, 0.03, 0.68, 1.  , 0.  , 0.02, 0.99, 0.09, 0.01,\n",
       "       1.  , 0.61, 1.  , 1.  , 0.71, 1.  , 0.78, 0.03, 1.  , 0.01, 1.  ,\n",
       "       0.03, 0.02, 1.  , 0.02, 1.  , 1.  , 1.  , 1.  , 0.02, 0.01, 0.66,\n",
       "       0.99, 0.01, 0.  , 0.61, 0.  , 1.  , 0.08, 0.03, 0.11, 1.  , 0.02,\n",
       "       0.03, 1.  , 0.99, 1.  , 0.72, 0.01, 1.  , 1.  , 0.99, 0.96, 0.98,\n",
       "       0.99, 0.95, 0.03, 0.95, 0.07, 1.  , 0.98, 1.  , 0.  , 0.02, 1.  ,\n",
       "       0.04, 0.  , 0.06, 1.  , 1.  , 0.99, 0.06, 0.14, 0.01, 0.01, 0.99,\n",
       "       0.14, 1.  , 0.98, 1.  , 0.02, 1.  , 0.  , 0.08, 1.  , 0.09, 0.01,\n",
       "       0.99, 1.  , 1.  , 0.71, 0.99, 0.1 , 1.  , 0.03, 0.  , 0.09, 0.83,\n",
       "       1.  , 0.89, 1.  , 0.95, 0.  , 0.12, 0.01, 0.71, 1.  , 0.78, 1.  ,\n",
       "       0.02, 0.05, 0.02, 0.  , 0.  , 1.  , 1.  , 0.05, 1.  , 0.21, 1.  ,\n",
       "       0.13, 0.  , 0.  , 0.02, 0.02, 0.  , 0.01, 0.01, 0.04, 1.  , 1.  ,\n",
       "       1.  , 0.9 , 0.17, 0.99, 0.04, 0.83, 1.  , 0.96, 0.  , 0.64, 0.99,\n",
       "       1.  , 1.  , 1.  , 1.  , 0.98, 0.98, 0.01, 1.  , 1.  , 0.11, 1.  ,\n",
       "       0.  , 0.99, 0.01, 0.98, 0.05, 1.  , 1.  , 1.  , 0.  , 1.  , 0.98,\n",
       "       0.1 , 0.88, 1.  , 0.01, 0.66, 0.08, 0.66, 0.67, 0.01, 0.  , 0.99,\n",
       "       1.  , 1.  , 0.01, 0.22, 0.08, 0.2 , 1.  , 1.  , 0.  , 0.13, 1.  ,\n",
       "       0.95, 1.  , 0.86, 1.  , 1.  , 0.99, 1.  , 1.  , 1.  , 1.  , 0.82,\n",
       "       0.08, 0.  , 1.  , 0.  , 0.94, 0.16, 1.  , 0.  , 0.98, 1.  , 1.  ,\n",
       "       0.98, 0.95, 0.98, 0.01, 1.  , 0.16, 1.  , 1.  , 1.  , 0.01, 1.  ,\n",
       "       0.79, 0.  , 0.  , 1.  , 0.16, 1.  , 1.  , 0.14, 0.16, 1.  , 0.99,\n",
       "       1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.03, 1.  , 1.  , 0.99, 0.01,\n",
       "       1.  , 0.02, 0.01, 1.  , 0.  , 0.08, 0.03, 0.97, 0.21, 0.1 , 0.86,\n",
       "       0.05, 0.02, 0.04, 0.75, 0.03, 1.  , 1.  , 0.  , 0.  , 0.  , 0.76,\n",
       "       0.01, 1.  , 1.  , 1.  , 0.99, 0.  , 1.  , 0.  , 0.  , 0.  , 0.99,\n",
       "       0.01, 0.  , 0.99, 0.02, 1.  , 0.01, 0.02, 0.98, 1.  , 1.  , 0.03,\n",
       "       1.  , 0.  , 1.  , 0.  , 0.08, 0.96, 1.  , 0.98, 0.06, 0.04, 0.02,\n",
       "       1.  , 0.9 , 0.01, 0.97, 0.2 , 1.  , 1.  , 0.12, 1.  , 0.  , 0.  ,\n",
       "       1.  , 1.  , 1.  , 0.03, 0.21, 0.01, 1.  , 1.  , 0.  , 0.07, 0.09,\n",
       "       0.14, 0.  , 0.89, 1.  , 0.01, 0.85, 0.01, 0.07, 0.  , 1.  , 0.03,\n",
       "       0.03, 0.  , 1.  , 0.81, 1.  , 0.98, 0.  , 0.97, 1.  , 1.  , 0.01,\n",
       "       1.  , 0.98, 1.  , 0.8 , 0.11, 0.98, 1.  , 0.02, 1.  , 1.  , 0.05,\n",
       "       0.01, 1.  , 0.98, 0.78, 0.  , 0.03, 0.  , 0.01, 0.04, 0.04, 0.01,\n",
       "       0.  , 1.  , 0.01, 0.14, 0.  , 1.  , 0.02, 0.69, 0.  , 1.  , 0.99,\n",
       "       0.03, 0.18, 0.15, 0.01, 0.  , 0.1 , 0.03, 0.07, 1.  , 0.03, 0.99,\n",
       "       0.01, 0.05, 0.  , 1.  , 0.01, 0.08]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.fit(train_data, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_tuning_predicted = chain.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9725314368\n"
     ]
    }
   ],
   "source": [
    "bfr_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
    "                          y_score=before_tuning_predicted.predict)\n",
    "print(round(bfr_tun_roc_auc, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.945054945054945, 0.8775510204081632, 0.9137055837563451)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = precision_score(test_data.target,before_tuning_predicted.predict.round())\n",
    "r = recall_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "a = accuracy_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "p, r, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_model_types.remove('knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgboost'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_model_types[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit : roc_auc is  0.9692846836\n",
      "logit : precision is  0.9565217391304348\n",
      "logit : recall is  0.8979591836734694\n",
      "logit : accuracy is  0.9289340101522843 \n",
      "\n",
      "lda : roc_auc is  0.9580498866\n",
      "lda : precision is  0.9876543209876543\n",
      "lda : recall is  0.8163265306122449\n",
      "lda : accuracy is  0.9035532994923858 \n",
      "\n",
      "qda : roc_auc is  0.9612451041\n",
      "qda : precision is  0.9354838709677419\n",
      "qda : recall is  0.8877551020408163\n",
      "qda : accuracy is  0.9137055837563451 \n",
      "\n",
      "dt : roc_auc is  0.9032673676\n",
      "dt : precision is  0.9540229885057471\n",
      "dt : recall is  0.8469387755102041\n",
      "dt : accuracy is  0.9035532994923858 \n",
      "\n",
      "rf : roc_auc is  0.9788188002\n",
      "rf : precision is  0.946236559139785\n",
      "rf : recall is  0.8979591836734694\n",
      "rf : accuracy is  0.9238578680203046 \n",
      "\n",
      "mlp : roc_auc is  0.9633065347\n",
      "mlp : precision is  0.9361702127659575\n",
      "mlp : recall is  0.8979591836734694\n",
      "mlp : accuracy is  0.9187817258883249 \n",
      "\n",
      "knn : roc_auc is  0.9545454545\n",
      "knn : precision is  0.9555555555555556\n",
      "knn : recall is  0.8775510204081632\n",
      "knn : accuracy is  0.9187817258883249 \n",
      "\n",
      "svc : roc_auc is  0.9642341785\n",
      "svc : precision is  0.9565217391304348\n",
      "svc : recall is  0.8979591836734694\n",
      "svc : accuracy is  0.9289340101522843 \n",
      "\n",
      "xgboost : roc_auc is  0.9735106164\n",
      "xgboost : precision is  0.9361702127659575\n",
      "xgboost : recall is  0.8979591836734694\n",
      "xgboost : accuracy is  0.9187817258883249 \n",
      "\n",
      "bernb : roc_auc is  0.9516594517\n",
      "bernb : precision is  0.9875\n",
      "bernb : recall is  0.8061224489795918\n",
      "bernb : accuracy is  0.8984771573604061 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in available_model_types[:-1]:\n",
    "    chain = get_simple_chain(model)\n",
    "    chain.fit(train_data, use_cache=False)\n",
    "    before_tuning_predicted = chain.predict(test_data)\n",
    "    bfr_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
    "                          y_score=before_tuning_predicted.predict)\n",
    "    p = precision_score(test_data.target,before_tuning_predicted.predict.round())\n",
    "    r = recall_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "    a = accuracy_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "    print(model, ': roc_auc is ', round(bfr_tun_roc_auc, 10))\n",
    "    print(model, ': precision is ', p)\n",
    "    print(model, ': recall is ', r)\n",
    "    print(model, ': accuracy is ', a, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\creditcard\\\\train.csv'\n",
    "test_file_path = 'C:\\\\Users\\\\Тимур\\\\vir\\\\Scripts\\\\Fedot\\\\examples\\\\data\\\\creditcard\\\\test.csv'\n",
    "train_data = InputData.from_csv(train_file_path)\n",
    "test_data = InputData.from_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model b not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-55b09e40f4f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mavailable_model_types\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mchain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_simple_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mbefore_tuning_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     bfr_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
      "\u001b[1;32m~\\vir\\Scripts\\Fedot\\core\\composer\\chain.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, input_data, use_cache, verbose)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clean_model_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mtrain_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_predicted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\vir\\Scripts\\Fedot\\core\\composer\\node.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, input_data, verbose)\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Trying to fit primary node with model: {self.model}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mmodel_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_using_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         return OutputData(idx=input_data.idx,\n",
      "\u001b[1;32m~\\vir\\Scripts\\Fedot\\core\\composer\\node.py\u001b[0m in \u001b[0;36m_fit_using_cache\u001b[1;34m(self, input_data, with_preprocessing, verbose)\u001b[0m\n\u001b[0;32m     63\u001b[0m         preprocessed_data = transformation_function_for_data(\n\u001b[0;32m     64\u001b[0m             \u001b[0minput_data_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             required_data_types=self.model.metadata.input_types)(input_data)\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactual_cached_state\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\vir\\Scripts\\Fedot\\core\\models\\model.py\u001b[0m in \u001b[0;36mmetadata\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mmodel_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelTypesRepository\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_info_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Model {self.model_type} not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Model b not found"
     ]
    }
   ],
   "source": [
    "for model in available_model_types[:-1]:\n",
    "    chain = get_simple_chain(model)\n",
    "    chain.fit(train_data, use_cache=False)\n",
    "    before_tuning_predicted = chain.predict(test_data)\n",
    "    bfr_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
    "                          y_score=before_tuning_predicted.predict)\n",
    "    p = precision_score(test_data.target,before_tuning_predicted.predict.round())\n",
    "    r = recall_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "    a = accuracy_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "    print(model, ': roc_auc is ', round(bfr_tun_roc_auc, 10))\n",
    "    print(model, ': precision is ', p)\n",
    "    print(model, ': recall is ', r)\n",
    "    print(model, ': accuracy is ', a, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = get_simple_chain('svc')\n",
    "chain.fit(train_data, use_cache=False)\n",
    "before_tuning_predicted = chain.predict(test_data)\n",
    "bfr_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
    "                      y_score=before_tuning_predicted.predict)\n",
    "p = precision_score(test_data.target,before_tuning_predicted.predict.round())\n",
    "r = recall_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "a = accuracy_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "model = 'mod'\n",
    "print(model, ': roc_auc is ', round(bfr_tun_roc_auc, 10))\n",
    "print(model, ': precision is ', p)\n",
    "print(model, ': recall is ', r)\n",
    "print(model, ': accuracy is ', a, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999999663, 0.9998596097150078, 1.0, 0.9999296554877513)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(round(bfr_tun_roc_auc, 10), p, r, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit : roc_auc is  0.9872483007\n",
      "logit : precision is  0.975940548072457\n",
      "logit : recall is  0.9219671440606572\n",
      "logit : accuracy is  0.9495190193974993 \n",
      "\n",
      "lda : roc_auc is  0.9752322276\n",
      "lda : precision is  0.9850909090909091\n",
      "lda : recall is  0.8558340353833193\n",
      "lda : accuracy is  0.9212844907936619 \n",
      "\n",
      "qda : roc_auc is  0.9748670447\n",
      "qda : precision is  0.9617988577480238\n",
      "qda : recall is  0.8926214546475709\n",
      "qda : accuracy is  0.9284420449149711 \n",
      "\n",
      "dt : roc_auc is  0.999753304\n",
      "dt : precision is  0.9995088063995509\n",
      "dt : recall is  1.0\n",
      "dt : accuracy is  0.9997537942071294 \n",
      "\n",
      "rf : roc_auc is  1.0\n",
      "rf : precision is  0.9999297999297999\n",
      "rf : recall is  1.0\n",
      "rf : accuracy is  0.9999648277438756 \n",
      "\n",
      "mlp : roc_auc is  0.9999723312\n",
      "mlp : precision is  0.9994036134011577\n",
      "mlp : recall is  1.0\n",
      "mlp : accuracy is  0.9997010358229429 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in available_model_types[:-1]:\n",
    "    chain = get_simple_chain(model)\n",
    "    chain.fit(train_data, use_cache=False)\n",
    "    before_tuning_predicted = chain.predict(test_data)\n",
    "    bfr_tun_roc_auc = roc_auc(y_true=test_data.target,\n",
    "                          y_score=before_tuning_predicted.predict)\n",
    "    p = precision_score(test_data.target,before_tuning_predicted.predict.round())\n",
    "    r = recall_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "    a = accuracy_score(y_true=test_data.target, y_pred=before_tuning_predicted.predict.round())\n",
    "    print(model, ': roc_auc is ', round(bfr_tun_roc_auc, 10))\n",
    "    print(model, ': precision is ', p)\n",
    "    print(model, ': recall is ', r)\n",
    "    print(model, ': accuracy is ', a, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
